<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title># 9 Data Science | Learning notes : Linux, Devops, entre outros</title>
  <meta name="description" content="Those notes are for future reference" />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="# 9 Data Science | Learning notes : Linux, Devops, entre outros" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Those notes are for future reference" />
  <meta name="github-repo" content="rstudio/book-notes-linux-learn" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="# 9 Data Science | Learning notes : Linux, Devops, entre outros" />
  
  <meta name="twitter:description" content="Those notes are for future reference" />
  

<meta name="author" content="Bruno Machado" />


<meta name="date" content="2022-06-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="devops.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Learning Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Intro</a></li>
<li class="chapter" data-level="2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html"><i class="fa fa-check"></i><b>2</b> Server Administrator I - RH124</a><ul>
<li class="chapter" data-level="2.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#what-is-linux"><i class="fa fa-check"></i><b>2.1</b> What is linux ?</a></li>
<li class="chapter" data-level="2.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#command-line"><i class="fa fa-check"></i><b>2.2</b> Command Line</a><ul>
<li class="chapter" data-level="2.2.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#and"><i class="fa fa-check"></i><b>2.2.1</b> <code>$</code> and <code>#</code></a></li>
<li class="chapter" data-level="2.2.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#to-login-into-another-computer-using-ssh"><i class="fa fa-check"></i><b>2.2.2</b> To login into another computer using <code>ssh</code></a></li>
<li class="chapter" data-level="2.2.3" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#executing-commands"><i class="fa fa-check"></i><b>2.2.3</b> Executing commands</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#managing-file-system"><i class="fa fa-check"></i><b>2.3</b> Managing File system</a><ul>
<li class="chapter" data-level="2.3.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#the-file-system-hierarchy"><i class="fa fa-check"></i><b>2.3.1</b> The file system hierarchy <code>/</code></a></li>
<li class="chapter" data-level="2.3.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#absolute-and-relative-paths"><i class="fa fa-check"></i><b>2.3.2</b> Absolute and Relative paths</a></li>
<li class="chapter" data-level="2.3.3" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#managing-files"><i class="fa fa-check"></i><b>2.3.3</b> Managing Files</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#help"><i class="fa fa-check"></i><b>2.4</b> Help</a></li>
<li class="chapter" data-level="2.5" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#text-files"><i class="fa fa-check"></i><b>2.5</b> Text Files</a><ul>
<li class="chapter" data-level="2.5.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#vim"><i class="fa fa-check"></i><b>2.5.1</b> vim</a></li>
<li class="chapter" data-level="2.5.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#changing-shell"><i class="fa fa-check"></i><b>2.5.2</b> Changing shell</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#managing-local-users-and-groups"><i class="fa fa-check"></i><b>2.6</b> Managing Local Users and Groups</a><ul>
<li class="chapter" data-level="2.6.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#users"><i class="fa fa-check"></i><b>2.6.1</b> Users</a></li>
<li class="chapter" data-level="2.6.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#groups"><i class="fa fa-check"></i><b>2.6.2</b> Groups</a></li>
<li class="chapter" data-level="2.6.3" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#gaining-superuser-access"><i class="fa fa-check"></i><b>2.6.3</b> Gaining superuser access</a></li>
<li class="chapter" data-level="2.6.4" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#managing-user-passwords"><i class="fa fa-check"></i><b>2.6.4</b> Managing user passwords</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#controlling-access-to-files"><i class="fa fa-check"></i><b>2.7</b> Controlling access to files</a><ul>
<li class="chapter" data-level="2.7.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#special-permissions"><i class="fa fa-check"></i><b>2.7.1</b> Special permissions</a></li>
<li class="chapter" data-level="2.7.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#default-permissions---umask"><i class="fa fa-check"></i><b>2.7.2</b> Default permissions - umask</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#monitoring-and-managing-linux-process"><i class="fa fa-check"></i><b>2.8</b> Monitoring and Managing Linux process</a><ul>
<li class="chapter" data-level="2.8.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#commands-to-monitor"><i class="fa fa-check"></i><b>2.8.1</b> Commands to monitor</a></li>
<li class="chapter" data-level="2.8.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#controlling-jobs"><i class="fa fa-check"></i><b>2.8.2</b> Controlling jobs</a></li>
<li class="chapter" data-level="2.8.3" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#killing-process"><i class="fa fa-check"></i><b>2.8.3</b> Killing process</a></li>
<li class="chapter" data-level="2.8.4" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#monitor-process-activity"><i class="fa fa-check"></i><b>2.8.4</b> Monitor process activity</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#controlling-services-and-daemons"><i class="fa fa-check"></i><b>2.9</b> Controlling Services and Daemons</a></li>
<li class="chapter" data-level="2.10" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#configuring-and-securing-ssh"><i class="fa fa-check"></i><b>2.10</b> Configuring and Securing SSH</a><ul>
<li class="chapter" data-level="2.10.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#configure-ssh-key-based-authentication"><i class="fa fa-check"></i><b>2.10.1</b> Configure SSH Key-based Authentication</a></li>
<li class="chapter" data-level="2.10.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#create-a-public-and-private-keypair"><i class="fa fa-check"></i><b>2.10.2</b> Create a public and private keypair</a></li>
<li class="chapter" data-level="2.10.3" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#customizing-openssh-service-config"><i class="fa fa-check"></i><b>2.10.3</b> Customizing OpenSSH Service Config</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#analysing-and-storing-logs"><i class="fa fa-check"></i><b>2.11</b> Analysing and Storing Logs</a><ul>
<li class="chapter" data-level="2.11.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#reviewing-system-hournal-entries"><i class="fa fa-check"></i><b>2.11.1</b> Reviewing System Hournal Entries</a></li>
<li class="chapter" data-level="2.11.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#preserving-the-system-journal"><i class="fa fa-check"></i><b>2.11.2</b> Preserving the system journal</a></li>
<li class="chapter" data-level="2.11.3" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#maitaining-accurate-time"><i class="fa fa-check"></i><b>2.11.3</b> Maitaining Accurate time</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#managing-networking"><i class="fa fa-check"></i><b>2.12</b> Managing Networking</a><ul>
<li class="chapter" data-level="2.12.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#tcpip"><i class="fa fa-check"></i><b>2.12.1</b> TCPIP</a></li>
<li class="chapter" data-level="2.12.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#validating-network-configuration"><i class="fa fa-check"></i><b>2.12.2</b> Validating Network Configuration</a></li>
<li class="chapter" data-level="2.12.3" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#configure-networking-from-the-command-line"><i class="fa fa-check"></i><b>2.12.3</b> Configure Networking from the Command Line</a></li>
<li class="chapter" data-level="2.12.4" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#editing-network-configuration-files"><i class="fa fa-check"></i><b>2.12.4</b> Editing Network Configuration Files</a></li>
<li class="chapter" data-level="2.12.5" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#configuring-hot-names-and-name-resolution"><i class="fa fa-check"></i><b>2.12.5</b> Configuring Hot Names and Name Resolution</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#archiving-and-transferring-files"><i class="fa fa-check"></i><b>2.13</b> Archiving and transferring files</a><ul>
<li class="chapter" data-level="2.13.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#tar"><i class="fa fa-check"></i><b>2.13.1</b> TAR</a></li>
<li class="chapter" data-level="2.13.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#scp"><i class="fa fa-check"></i><b>2.13.2</b> SCP</a></li>
<li class="chapter" data-level="2.13.3" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#sftp"><i class="fa fa-check"></i><b>2.13.3</b> SFTP</a></li>
<li class="chapter" data-level="2.13.4" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#synchronizing-files-between-system"><i class="fa fa-check"></i><b>2.13.4</b> Synchronizing Files Between System</a></li>
</ul></li>
<li class="chapter" data-level="2.14" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#intalling-and-updating-software-packages"><i class="fa fa-check"></i><b>2.14</b> Intalling and updating software packages</a><ul>
<li class="chapter" data-level="2.14.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#package-manager"><i class="fa fa-check"></i><b>2.14.1</b> Package manager</a></li>
<li class="chapter" data-level="2.14.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#inslalling-and-update-software-packages-with-yum"><i class="fa fa-check"></i><b>2.14.2</b> Inslalling and Update Software Packages with <strong>Yum</strong></a></li>
<li class="chapter" data-level="2.14.3" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#enabling-yum-software-repositories"><i class="fa fa-check"></i><b>2.14.3</b> Enabling Yum Software Repositories</a></li>
<li class="chapter" data-level="2.14.4" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#managing-packages-module-streams"><i class="fa fa-check"></i><b>2.14.4</b> Managing Packages Module Streams</a></li>
</ul></li>
<li class="chapter" data-level="2.15" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#accessing-linux-file-systems"><i class="fa fa-check"></i><b>2.15</b> Accessing Linux File Systems</a><ul>
<li class="chapter" data-level="2.15.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#mount-and-unmounting-file-systems"><i class="fa fa-check"></i><b>2.15.1</b> Mount and Unmounting File systems</a></li>
<li class="chapter" data-level="2.15.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#locating-files-on-the-system"><i class="fa fa-check"></i><b>2.15.2</b> Locating Files on the System</a></li>
</ul></li>
<li class="chapter" data-level="2.16" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#analysing-server-and-getting-support"><i class="fa fa-check"></i><b>2.16</b> Analysing Server and Getting Support</a><ul>
<li class="chapter" data-level="2.16.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#deteting-and-resolving-issues-with-red-hat-insights"><i class="fa fa-check"></i><b>2.16.1</b> Deteting and Resolving issues with Red Hat Insights</a></li>
</ul></li>
<li class="chapter" data-level="2.17" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#extra"><i class="fa fa-check"></i><b>2.17</b> Extra</a><ul>
<li class="chapter" data-level="2.17.1" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#create-8g-file-disk"><i class="fa fa-check"></i><b>2.17.1</b> Create 8G file disk</a></li>
<li class="chapter" data-level="2.17.2" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#find-users-wit-set-uid"><i class="fa fa-check"></i><b>2.17.2</b> Find users wit Set UID</a></li>
<li class="chapter" data-level="2.17.3" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#show-dump-device"><i class="fa fa-check"></i><b>2.17.3</b> Show dump device</a></li>
<li class="chapter" data-level="2.17.4" data-path="server-administrator-i---rh124.html"><a href="server-administrator-i---rh124.html#configure-labels-of-fs"><i class="fa fa-check"></i><b>2.17.4</b> Configure labels of FS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html"><i class="fa fa-check"></i><b>3</b> Server Administrator II - RH134</a><ul>
<li class="chapter" data-level="3.1" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#improving-command-line-productivity"><i class="fa fa-check"></i><b>3.1</b> Improving Command Line Productivity</a></li>
<li class="chapter" data-level="3.2" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#scheduling-future-tasks"><i class="fa fa-check"></i><b>3.2</b> Scheduling Future Tasks</a></li>
<li class="chapter" data-level="3.3" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#tuning-system-performance"><i class="fa fa-check"></i><b>3.3</b> Tuning System Performance</a><ul>
<li class="chapter" data-level="3.3.1" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#profiles"><i class="fa fa-check"></i><b>3.3.1</b> Profiles</a></li>
<li class="chapter" data-level="3.3.2" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#managing-profiles-from-command-line"><i class="fa fa-check"></i><b>3.3.2</b> Managing profiles from command line</a></li>
<li class="chapter" data-level="3.3.3" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#influencing-process-scheduling"><i class="fa fa-check"></i><b>3.3.3</b> Influencing Process Scheduling</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#controling-access-to-files-with-acls"><i class="fa fa-check"></i><b>3.4</b> Controling Access to Files with ACLs</a></li>
<li class="chapter" data-level="3.5" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#managing-selinux-security"><i class="fa fa-check"></i><b>3.5</b> Managing SELinux Security</a><ul>
<li class="chapter" data-level="3.5.1" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#controlling-selinux-file-contexts"><i class="fa fa-check"></i><b>3.5.1</b> Controlling SELinux File Contexts</a></li>
<li class="chapter" data-level="3.5.2" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#adjusting-selinux-policy-with-booleans"><i class="fa fa-check"></i><b>3.5.2</b> Adjusting SELinux Policy with Booleans</a></li>
<li class="chapter" data-level="3.5.3" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#investigating-and-resolving-selinux-issues"><i class="fa fa-check"></i><b>3.5.3</b> Investigating and REsolving SELinux issues</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#managing-basic-storage"><i class="fa fa-check"></i><b>3.6</b> Managing Basic Storage</a><ul>
<li class="chapter" data-level="3.6.1" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#adding-partition-file-systems-and-persistent-mounts"><i class="fa fa-check"></i><b>3.6.1</b> Adding Partition, File Systems and Persistent Mounts</a></li>
<li class="chapter" data-level="3.6.2" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#managing-swap-space"><i class="fa fa-check"></i><b>3.6.2</b> Managing Swap Space</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#managing-logical-volumes"><i class="fa fa-check"></i><b>3.7</b> Managing Logical Volumes</a><ul>
<li class="chapter" data-level="3.7.1" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#creating-logical-volumes"><i class="fa fa-check"></i><b>3.7.1</b> Creating Logical Volumes</a></li>
<li class="chapter" data-level="3.7.2" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#extending-and-reducing-logical-volumes"><i class="fa fa-check"></i><b>3.7.2</b> Extending and Reducing Logical Volumes</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#implementing-advanced-storage-features"><i class="fa fa-check"></i><b>3.8</b> Implementing Advanced Storage Features</a><ul>
<li class="chapter" data-level="3.8.1" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#managing-storage-with-stratis"><i class="fa fa-check"></i><b>3.8.1</b> Managing Storage with Stratis</a></li>
<li class="chapter" data-level="3.8.2" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#compressing-and-deduplicating-storage-with-vdo"><i class="fa fa-check"></i><b>3.8.2</b> Compressing and Deduplicating Storage with VDO</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#accessing-network-attached-storage"><i class="fa fa-check"></i><b>3.9</b> Accessing Network-Attached Storage</a><ul>
<li class="chapter" data-level="3.9.1" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#mounting-network-attached-storage-with-nfs"><i class="fa fa-check"></i><b>3.9.1</b> Mounting Network-Attached Storage with NFS</a></li>
<li class="chapter" data-level="3.9.2" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#automounting-network-attached-storage"><i class="fa fa-check"></i><b>3.9.2</b> Automounting Network-Attached Storage</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#controlling-the-boot-process"><i class="fa fa-check"></i><b>3.10</b> Controlling The Boot Process</a><ul>
<li class="chapter" data-level="3.10.1" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#selecting-the-boot-target"><i class="fa fa-check"></i><b>3.10.1</b> Selecting the boot target</a></li>
<li class="chapter" data-level="3.10.2" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#resetting-the-root-password"><i class="fa fa-check"></i><b>3.10.2</b> Resetting the Root Password</a></li>
<li class="chapter" data-level="3.10.3" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#repairing-file-system-issues-at-boot"><i class="fa fa-check"></i><b>3.10.3</b> Repairing File system Issues at Boot</a></li>
<li class="chapter" data-level="3.10.4" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#create-or-alter-grub"><i class="fa fa-check"></i><b>3.10.4</b> Create or alter grub</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#managing-network-security"><i class="fa fa-check"></i><b>3.11</b> Managing Network Security</a><ul>
<li class="chapter" data-level="3.11.1" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#managing-server-firewall"><i class="fa fa-check"></i><b>3.11.1</b> Managing Server Firewall</a></li>
<li class="chapter" data-level="3.11.2" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#controlling-selinux-port-labeling"><i class="fa fa-check"></i><b>3.11.2</b> Controlling SELinux Port Labeling</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#installing-red-hat-enterprise-linux"><i class="fa fa-check"></i><b>3.12</b> Installing Red Hat Enterprise Linux</a><ul>
<li class="chapter" data-level="3.12.1" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#installing-red-hat-enterprise-linux-1"><i class="fa fa-check"></i><b>3.12.1</b> Installing Red Hat Enterprise Linux</a></li>
<li class="chapter" data-level="3.12.2" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#automating-installation-with-kickstart"><i class="fa fa-check"></i><b>3.12.2</b> Automating Installation with Kickstart</a></li>
<li class="chapter" data-level="3.12.3" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#installing-and-configuring-virtual-machine"><i class="fa fa-check"></i><b>3.12.3</b> Installing and Configuring Virtual Machine</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#running-containers"><i class="fa fa-check"></i><b>3.13</b> Running Containers</a><ul>
<li class="chapter" data-level="3.13.1" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#intro-1"><i class="fa fa-check"></i><b>3.13.1</b> Intro</a></li>
<li class="chapter" data-level="3.13.2" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#running-a-basic-conatiner"><i class="fa fa-check"></i><b>3.13.2</b> Running a Basic Conatiner</a></li>
<li class="chapter" data-level="3.13.3" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#finding-and-managing-container-images"><i class="fa fa-check"></i><b>3.13.3</b> Finding and Managing Container Images</a></li>
<li class="chapter" data-level="3.13.4" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#performing-advanced-container-management"><i class="fa fa-check"></i><b>3.13.4</b> Performing Advanced Container Management</a></li>
<li class="chapter" data-level="3.13.5" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#attaching-persistent-storage-to-a-container"><i class="fa fa-check"></i><b>3.13.5</b> Attaching Persistent Storage to a Container</a></li>
<li class="chapter" data-level="3.13.6" data-path="server-administrator-ii---rh134.html"><a href="server-administrator-ii---rh134.html#managing-containers-as-service"><i class="fa fa-check"></i><b>3.13.6</b> Managing Containers as Service</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html"><i class="fa fa-check"></i><b>4</b> Server Administrator III - RH294</a><ul>
<li class="chapter" data-level="4.1" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#intro-to-ansible"><i class="fa fa-check"></i><b>4.1</b> Intro to Ansible</a><ul>
<li class="chapter" data-level="4.1.1" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#ansible-concepts-and-architecture"><i class="fa fa-check"></i><b>4.1.1</b> Ansible Concepts and Architecture</a></li>
<li class="chapter" data-level="4.1.2" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#install-ansbile"><i class="fa fa-check"></i><b>4.1.2</b> Install Ansbile</a></li>
<li class="chapter" data-level="4.1.3" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#implementing-an-ansible-playbook"><i class="fa fa-check"></i><b>4.1.3</b> Implementing an Ansible Playbook</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#deploying-anisble-and-implementing-playbooks"><i class="fa fa-check"></i><b>4.2</b> Deploying Anisble and Implementing Playbooks</a><ul>
<li class="chapter" data-level="4.2.1" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#building-an-ansible-invetory"><i class="fa fa-check"></i><b>4.2.1</b> Building an Ansible Invetory</a></li>
<li class="chapter" data-level="4.2.2" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#managing-ansible-configuration-files"><i class="fa fa-check"></i><b>4.2.2</b> Managing Ansible Configuration Files</a></li>
<li class="chapter" data-level="4.2.3" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#running-ad-hoc-commands"><i class="fa fa-check"></i><b>4.2.3</b> Running Ad Hoc Commands</a></li>
<li class="chapter" data-level="4.2.4" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#writing-and-running-playbooks"><i class="fa fa-check"></i><b>4.2.4</b> Writing and Running Playbooks</a></li>
<li class="chapter" data-level="4.2.5" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#running-playbooks"><i class="fa fa-check"></i><b>4.2.5</b> Running Playbooks</a></li>
<li class="chapter" data-level="4.2.6" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#implementing-muliple-plays"><i class="fa fa-check"></i><b>4.2.6</b> Implementing Muliple Plays</a></li>
<li class="chapter" data-level="4.2.7" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#finding-modules-for-task"><i class="fa fa-check"></i><b>4.2.7</b> Finding Modules for Task</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#managing-variables-and-facts"><i class="fa fa-check"></i><b>4.3</b> Managing Variables and Facts</a><ul>
<li class="chapter" data-level="4.3.1" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#variables-in-playbook"><i class="fa fa-check"></i><b>4.3.1</b> Variables in playbook</a></li>
<li class="chapter" data-level="4.3.2" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#host-and-group-variables"><i class="fa fa-check"></i><b>4.3.2</b> Host and group variables</a></li>
<li class="chapter" data-level="4.3.3" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#using-directories-to-populate-host-and-group-variables"><i class="fa fa-check"></i><b>4.3.3</b> Using directories to populate host and group variables</a></li>
<li class="chapter" data-level="4.3.4" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#overrding-variable-from-command-line"><i class="fa fa-check"></i><b>4.3.4</b> Overrding variable from command line</a></li>
<li class="chapter" data-level="4.3.5" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#secrets"><i class="fa fa-check"></i><b>4.3.5</b> Secrets</a></li>
<li class="chapter" data-level="4.3.6" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#managing-facts"><i class="fa fa-check"></i><b>4.3.6</b> Managing Facts</a></li>
<li class="chapter" data-level="4.3.7" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#magic-variables"><i class="fa fa-check"></i><b>4.3.7</b> Magic Variables</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#implementing-task-control"><i class="fa fa-check"></i><b>4.4</b> Implementing Task Control</a><ul>
<li class="chapter" data-level="4.4.1" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#loops"><i class="fa fa-check"></i><b>4.4.1</b> Loops</a></li>
<li class="chapter" data-level="4.4.2" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#task-conditionally"><i class="fa fa-check"></i><b>4.4.2</b> Task Conditionally</a></li>
<li class="chapter" data-level="4.4.3" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#handlers"><i class="fa fa-check"></i><b>4.4.3</b> Handlers</a></li>
<li class="chapter" data-level="4.4.4" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#blocks"><i class="fa fa-check"></i><b>4.4.4</b> Blocks</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#deploying-files-to-managed-hosts"><i class="fa fa-check"></i><b>4.5</b> Deploying Files to Managed Hosts</a><ul>
<li class="chapter" data-level="4.5.1" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#modifying-and-copying-files-to-hosts"><i class="fa fa-check"></i><b>4.5.1</b> Modifying and Copying Files to hosts</a></li>
<li class="chapter" data-level="4.5.2" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#deploying-custom-files-with-jinja2-templates"><i class="fa fa-check"></i><b>4.5.2</b> Deploying Custom files with Jinja2 templates</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#managing-complex-plays-and-playbooks"><i class="fa fa-check"></i><b>4.6</b> Managing Complex Plays and Playbooks</a><ul>
<li class="chapter" data-level="4.6.1" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#selecting-hosts-with-host-patterns"><i class="fa fa-check"></i><b>4.6.1</b> Selecting Hosts with Host Patterns</a></li>
<li class="chapter" data-level="4.6.2" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#including-and-importing-files"><i class="fa fa-check"></i><b>4.6.2</b> Including and Importing Files</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#simplifying-playbooks-with-roles"><i class="fa fa-check"></i><b>4.7</b> Simplifying Playbooks with Roles</a><ul>
<li class="chapter" data-level="4.7.1" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#describing-role-structure"><i class="fa fa-check"></i><b>4.7.1</b> Describing Role Structure</a></li>
<li class="chapter" data-level="4.7.2" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#reusing-content-with-system-roles"><i class="fa fa-check"></i><b>4.7.2</b> Reusing Content with System Roles</a></li>
<li class="chapter" data-level="4.7.3" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#creating-roles"><i class="fa fa-check"></i><b>4.7.3</b> Creating Roles</a></li>
<li class="chapter" data-level="4.7.4" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#deploying-roles-with-ansible-galaxy"><i class="fa fa-check"></i><b>4.7.4</b> Deploying Roles with Ansible Galaxy</a></li>
<li class="chapter" data-level="4.7.5" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#roles-and-modules-from-content-collections"><i class="fa fa-check"></i><b>4.7.5</b> Roles and Modules from Content Collections</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#troubleshooting-ansible"><i class="fa fa-check"></i><b>4.8</b> Troubleshooting Ansible</a><ul>
<li class="chapter" data-level="4.8.1" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#troubleshooting-playbooks"><i class="fa fa-check"></i><b>4.8.1</b> Troubleshooting Playbooks</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#automating-linux-administration-tasks"><i class="fa fa-check"></i><b>4.9</b> Automating Linux Administration Tasks</a><ul>
<li class="chapter" data-level="4.9.1" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#managing-software-and-subscriptions"><i class="fa fa-check"></i><b>4.9.1</b> Managing Software and Subscriptions</a></li>
<li class="chapter" data-level="4.9.2" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#managing-users-and-authenticatin"><i class="fa fa-check"></i><b>4.9.2</b> Managing Users and Authenticatin</a></li>
<li class="chapter" data-level="4.9.3" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#managing-the-boot-process-and-scheduled-processes"><i class="fa fa-check"></i><b>4.9.3</b> Managing the Boot Process and Scheduled Processes</a></li>
<li class="chapter" data-level="4.9.4" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#managing-storage"><i class="fa fa-check"></i><b>4.9.4</b> Managing Storage</a></li>
<li class="chapter" data-level="4.9.5" data-path="server-administrator-iii---rh294.html"><a href="server-administrator-iii---rh294.html#managing-network-configuration"><i class="fa fa-check"></i><b>4.9.5</b> Managing Network Configuration</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html"><i class="fa fa-check"></i><b>5</b> Red Hat OpenShift I: Containers &amp; Kubernetes - DO180</a><ul>
<li class="chapter" data-level="5.1" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#intro-to-container"><i class="fa fa-check"></i><b>5.1</b> Intro to Container</a><ul>
<li class="chapter" data-level="5.1.1" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#linux-conetainer-architecture"><i class="fa fa-check"></i><b>5.1.1</b> Linux Conetainer Architecture</a></li>
<li class="chapter" data-level="5.1.2" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#overview-of-kubernetes-and-openshift"><i class="fa fa-check"></i><b>5.1.2</b> Overview of kubernetes and OpenShift</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#creating-containerized-services"><i class="fa fa-check"></i><b>5.2</b> Creating Containerized Services</a></li>
<li class="chapter" data-level="5.3" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#managing-containers"><i class="fa fa-check"></i><b>5.3</b> Managing Containers</a><ul>
<li class="chapter" data-level="5.3.1" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#container-life-cybe-management-with-podman"><i class="fa fa-check"></i><b>5.3.1</b> Container Life Cybe management with podman</a></li>
<li class="chapter" data-level="5.3.2" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#creating-containers"><i class="fa fa-check"></i><b>5.3.2</b> Creating containers</a></li>
<li class="chapter" data-level="5.3.3" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#run-commands-in-a-container"><i class="fa fa-check"></i><b>5.3.3</b> Run commands in a container</a></li>
<li class="chapter" data-level="5.3.4" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#managing-containers-1"><i class="fa fa-check"></i><b>5.3.4</b> Managing containers</a></li>
<li class="chapter" data-level="5.3.5" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#attaching-persistent-storage-to-containers"><i class="fa fa-check"></i><b>5.3.5</b> Attaching persistent storage to containers</a></li>
<li class="chapter" data-level="5.3.6" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#accessing-containers"><i class="fa fa-check"></i><b>5.3.6</b> Accessing containers</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#managing-container-images"><i class="fa fa-check"></i><b>5.4</b> Managing Container Images</a><ul>
<li class="chapter" data-level="5.4.1" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#accessing-registries"><i class="fa fa-check"></i><b>5.4.1</b> Accessing Registries</a></li>
<li class="chapter" data-level="5.4.2" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#manipulating-container-images"><i class="fa fa-check"></i><b>5.4.2</b> Manipulating Container Images</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#creating-custom-container-images"><i class="fa fa-check"></i><b>5.5</b> Creating Custom Container Images</a><ul>
<li class="chapter" data-level="5.5.1" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#designing-custom-container-images"><i class="fa fa-check"></i><b>5.5.1</b> Designing Custom Container Images</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#deploying-containerized-applications-on-openshift"><i class="fa fa-check"></i><b>5.6</b> Deploying Containerized Applications on OpenShift</a><ul>
<li class="chapter" data-level="5.6.1" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#describing-kubernetes-and-openshift-architecture"><i class="fa fa-check"></i><b>5.6.1</b> Describing Kubernetes and OpenShift Architecture</a></li>
<li class="chapter" data-level="5.6.2" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#creating-kubernetes-resources"><i class="fa fa-check"></i><b>5.6.2</b> Creating Kubernetes Resources</a></li>
<li class="chapter" data-level="5.6.3" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#creating-routes"><i class="fa fa-check"></i><b>5.6.3</b> Creating Routes</a></li>
<li class="chapter" data-level="5.6.4" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#creating-applications-with-source-to-image"><i class="fa fa-check"></i><b>5.6.4</b> Creating Applications with Source-to-Image</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#deploying-multi-container-applications"><i class="fa fa-check"></i><b>5.7</b> Deploying Multi-Container Applications</a><ul>
<li class="chapter" data-level="5.7.1" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#considerations-for-multi-container-applications"><i class="fa fa-check"></i><b>5.7.1</b> Considerations for Multi-Container Applications</a></li>
<li class="chapter" data-level="5.7.2" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#deploying-a-multi-container-app-on-openshift"><i class="fa fa-check"></i><b>5.7.2</b> Deploying A Multi-Container App on OpenShift</a></li>
<li class="chapter" data-level="5.7.3" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#deploying-a-multi-container-application-on-openshift-using-a-template"><i class="fa fa-check"></i><b>5.7.3</b> Deploying a Multi-container Application on OpenShift Using a Template</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#troubleshooting-containerized-applications"><i class="fa fa-check"></i><b>5.8</b> Troubleshooting Containerized Applications</a><ul>
<li class="chapter" data-level="5.8.1" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#troubleshooting-s2i-builds-and-deployments"><i class="fa fa-check"></i><b>5.8.1</b> Troubleshooting S2I Builds and Deployments</a></li>
<li class="chapter" data-level="5.8.2" data-path="red-hat-openshift-i-containers-kubernetes---do180.html"><a href="red-hat-openshift-i-containers-kubernetes---do180.html#troubleshooting-containerized-applications-1"><i class="fa fa-check"></i><b>5.8.2</b> Troubleshooting Containerized Applications</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><i class="fa fa-check"></i><b>6</b> Red Hat OpenShift Administration II: Operating a Production Kubernetes Cluster - DO280</a><ul>
<li class="chapter" data-level="6.1" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#describing-the-red-hat-openshift-container-plataform"><i class="fa fa-check"></i><b>6.1</b> Describing the Red Hat OpenShift Container Plataform</a><ul>
<li class="chapter" data-level="6.1.1" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#describing-openshift-container-platform"><i class="fa fa-check"></i><b>6.1.1</b> Describing OpenShift Container Platform</a></li>
<li class="chapter" data-level="6.1.2" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#architecture-of-openshift"><i class="fa fa-check"></i><b>6.1.2</b> Architecture of OpenShift</a></li>
<li class="chapter" data-level="6.1.3" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#cluster-operators"><i class="fa fa-check"></i><b>6.1.3</b> Cluster Operators</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#verifying-the-health-of-a-cluster"><i class="fa fa-check"></i><b>6.2</b> Verifying the Health of a Cluster</a><ul>
<li class="chapter" data-level="6.2.1" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#intro-to-openshift-installtion-methods"><i class="fa fa-check"></i><b>6.2.1</b> Intro to OpenShift Installtion Methods</a></li>
<li class="chapter" data-level="6.2.2" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#troubleshooting-openshit-cluster-and-applications"><i class="fa fa-check"></i><b>6.2.2</b> Troubleshooting OpenShit Cluster and Applications</a></li>
<li class="chapter" data-level="6.2.3" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#introducing-openshift-dynamic-storage"><i class="fa fa-check"></i><b>6.2.3</b> Introducing OpenShift Dynamic Storage</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#configuring-authentication-and-authorization"><i class="fa fa-check"></i><b>6.3</b> Configuring Authentication and Authorization</a><ul>
<li class="chapter" data-level="6.3.1" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#identity"><i class="fa fa-check"></i><b>6.3.1</b> Identity</a></li>
<li class="chapter" data-level="6.3.2" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#configuring-the-htpasswd-identity-provider"><i class="fa fa-check"></i><b>6.3.2</b> Configuring the HTPasswd Identity Provider</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#configuring-application-security"><i class="fa fa-check"></i><b>6.4</b> Configuring Application Security</a><ul>
<li class="chapter" data-level="6.4.1" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#managing-sensitive-information-with-secrets"><i class="fa fa-check"></i><b>6.4.1</b> Managing Sensitive Information with secrets</a></li>
<li class="chapter" data-level="6.4.2" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#controlling-application-permissions-with-security-contect-contrainst"><i class="fa fa-check"></i><b>6.4.2</b> Controlling Application Permissions with Security Contect Contrainst</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#configuring-openshift-networking-for-applications"><i class="fa fa-check"></i><b>6.5</b> Configuring OpenShift Networking For Applications</a><ul>
<li class="chapter" data-level="6.5.1" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#openshift-software-defined-networking"><i class="fa fa-check"></i><b>6.5.1</b> OpenShift Software-defined Networking</a></li>
<li class="chapter" data-level="6.5.2" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#exposing-applications-for-external-access"><i class="fa fa-check"></i><b>6.5.2</b> Exposing Applications for External Access</a></li>
<li class="chapter" data-level="6.5.3" data-path="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html"><a href="red-hat-openshift-administration-ii-operating-a-production-kubernetes-cluster---do280.html#configuring-network-policies"><i class="fa fa-check"></i><b>6.5.3</b> Configuring Network Policies</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="7" data-path="cloud.html"><a href="cloud.html"><i class="fa fa-check"></i><b>7</b> Cloud</a><ul>
<li class="chapter" data-level="7.1" data-path="cloud.html"><a href="cloud.html#azure"><i class="fa fa-check"></i><b>7.1</b> Azure</a></li>
<li class="chapter" data-level="7.2" data-path="cloud.html"><a href="cloud.html#aws"><i class="fa fa-check"></i><b>7.2</b> AWS</a><ul>
<li class="chapter" data-level="7.2.1" data-path="cloud.html"><a href="cloud.html#part-1-cloud-concepts"><i class="fa fa-check"></i><b>7.2.1</b> Part 1 : Cloud Concepts</a></li>
<li class="chapter" data-level="7.2.2" data-path="cloud.html"><a href="cloud.html#part-2-foundation"><i class="fa fa-check"></i><b>7.2.2</b> Part 2 : Foundation</a></li>
<li class="chapter" data-level="7.2.3" data-path="cloud.html"><a href="cloud.html#part-3-aws-well-architected"><i class="fa fa-check"></i><b>7.2.3</b> Part 3 : AWS Well-Architected</a></li>
<li class="chapter" data-level="7.2.4" data-path="cloud.html"><a href="cloud.html#part-4-iam"><i class="fa fa-check"></i><b>7.2.4</b> Part 4 : IAM</a></li>
<li class="chapter" data-level="7.2.5" data-path="cloud.html"><a href="cloud.html#part-5-iam-cont"><i class="fa fa-check"></i><b>7.2.5</b> Part 5 : IAM cont</a></li>
<li class="chapter" data-level="7.2.6" data-path="cloud.html"><a href="cloud.html#part-6-ec2"><i class="fa fa-check"></i><b>7.2.6</b> Part 6 : EC2</a></li>
<li class="chapter" data-level="7.2.7" data-path="cloud.html"><a href="cloud.html#part-7-ec2-cont"><i class="fa fa-check"></i><b>7.2.7</b> Part 7 : EC2 cont </a></li>
<li class="chapter" data-level="7.2.8" data-path="cloud.html"><a href="cloud.html#part-8-9-and-10-vpc"><i class="fa fa-check"></i><b>7.2.8</b> Part 8 , 9 and 10 : VPC</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="cloud.html"><a href="cloud.html#gcp"><i class="fa fa-check"></i><b>7.3</b> GCP</a><ul>
<li class="chapter" data-level="7.3.1" data-path="cloud.html"><a href="cloud.html#digital-leader"><i class="fa fa-check"></i><b>7.3.1</b> Digital Leader</a></li>
<li class="chapter" data-level="7.3.2" data-path="cloud.html"><a href="cloud.html#cloud-engineer"><i class="fa fa-check"></i><b>7.3.2</b> Cloud Engineer</a></li>
<li class="chapter" data-level="7.3.3" data-path="cloud.html"><a href="cloud.html#machine-learning-engineer"><i class="fa fa-check"></i><b>7.3.3</b> Machine Learning Engineer</a></li>
<li class="chapter" data-level="7.3.4" data-path="cloud.html"><a href="cloud.html#data-engineer"><i class="fa fa-check"></i><b>7.3.4</b> Data Engineer</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="devops.html"><a href="devops.html"><i class="fa fa-check"></i><b>8</b> DevOps</a><ul>
<li class="chapter" data-level="8.1" data-path="devops.html"><a href="devops.html#docker"><i class="fa fa-check"></i><b>8.1</b> Docker</a><ul>
<li class="chapter" data-level="8.1.1" data-path="devops.html"><a href="devops.html#part-1"><i class="fa fa-check"></i><b>8.1.1</b> Part 1</a></li>
<li class="chapter" data-level="8.1.2" data-path="devops.html"><a href="devops.html#part-2"><i class="fa fa-check"></i><b>8.1.2</b> Part 2</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="devops.html"><a href="devops.html#jenkins"><i class="fa fa-check"></i><b>8.2</b> Jenkins</a><ul>
<li class="chapter" data-level="8.2.1" data-path="devops.html"><a href="devops.html#cicd"><i class="fa fa-check"></i><b>8.2.1</b> CI/CD</a></li>
<li class="chapter" data-level="8.2.2" data-path="devops.html"><a href="devops.html#install"><i class="fa fa-check"></i><b>8.2.2</b> Install</a></li>
<li class="chapter" data-level="8.2.3" data-path="devops.html"><a href="devops.html#arquitecture"><i class="fa fa-check"></i><b>8.2.3</b> Arquitecture</a></li>
<li class="chapter" data-level="8.2.4" data-path="devops.html"><a href="devops.html#job"><i class="fa fa-check"></i><b>8.2.4</b> Job</a></li>
<li class="chapter" data-level="8.2.5" data-path="devops.html"><a href="devops.html#git-github"><i class="fa fa-check"></i><b>8.2.5</b> Git &amp; GitHub</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="devops.html"><a href="devops.html#git"><i class="fa fa-check"></i><b>8.3</b> Git</a><ul>
<li class="chapter" data-level="8.3.1" data-path="devops.html"><a href="devops.html#intro-2"><i class="fa fa-check"></i><b>8.3.1</b> Intro</a></li>
<li class="chapter" data-level="8.3.2" data-path="devops.html"><a href="devops.html#setup-and-config"><i class="fa fa-check"></i><b>8.3.2</b> Setup and Config</a></li>
<li class="chapter" data-level="8.3.3" data-path="devops.html"><a href="devops.html#working-locally"><i class="fa fa-check"></i><b>8.3.3</b> Working Locally</a></li>
<li class="chapter" data-level="8.3.4" data-path="devops.html"><a href="devops.html#working-remote"><i class="fa fa-check"></i><b>8.3.4</b> Working Remote</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="data-science.html"><a href="data-science.html"><i class="fa fa-check"></i><b>9</b> Data Science</a><ul>
<li class="chapter" data-level="9.1" data-path="data-science.html"><a href="data-science.html#datacamp-python-skills-for-data-science"><i class="fa fa-check"></i><b>9.1</b> DataCamp Python Skills for Data Science</a><ul>
<li class="chapter" data-level="9.1.1" data-path="data-science.html"><a href="data-science.html#introduction-to-python"><i class="fa fa-check"></i><b>9.1.1</b> Introduction to Python</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="data-science.html"><a href="data-science.html#datacamp-r-skills-for-data-science"><i class="fa fa-check"></i><b>9.2</b> DataCamp R Skills for Data Science</a></li>
<li class="chapter" data-level="9.3" data-path="data-science.html"><a href="data-science.html#azure-data-science-certification"><i class="fa fa-check"></i><b>9.3</b> Azure Data Science Certification</a></li>
<li class="chapter" data-level="9.4" data-path="data-science.html"><a href="data-science.html#aws-data-science-certification"><i class="fa fa-check"></i><b>9.4</b> AWS Data Science Certification</a><ul>
<li class="chapter" data-level="9.4.1" data-path="data-science.html"><a href="data-science.html#demystifying-ai-ml-dl"><i class="fa fa-check"></i><b>9.4.1</b> Demystifying AI / ML / DL</a></li>
<li class="chapter" data-level="9.4.2" data-path="data-science.html"><a href="data-science.html#machine-learning-essentials-for-business-and-technical-decision-makers"><i class="fa fa-check"></i><b>9.4.2</b> Machine Learning Essentials for Business and Technical Decision Makers</a></li>
<li class="chapter" data-level="9.4.3" data-path="data-science.html"><a href="data-science.html#machine-learning-for-business-leaders"><i class="fa fa-check"></i><b>9.4.3</b> Machine Learning for Business Leaders</a></li>
<li class="chapter" data-level="9.4.4" data-path="data-science.html"><a href="data-science.html#process-model-crisp-dm-on-the-aws-stack"><i class="fa fa-check"></i><b>9.4.4</b> Process Model : CRISP-DM on the AWS Stack</a></li>
<li class="chapter" data-level="9.4.5" data-path="data-science.html"><a href="data-science.html#machine-learning-terminology-and-process"><i class="fa fa-check"></i><b>9.4.5</b> Machine Learning Terminology and Process</a></li>
<li class="chapter" data-level="9.4.6" data-path="data-science.html"><a href="data-science.html#data-engineering"><i class="fa fa-check"></i><b>9.4.6</b> Data Engineering</a></li>
<li class="chapter" data-level="9.4.7" data-path="data-science.html"><a href="data-science.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>9.4.7</b> Exploratory Data Analysis</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="data-science.html"><a href="data-science.html#gcp---professional-machin-e-learning-engineer"><i class="fa fa-check"></i><b>9.5</b> GCP - Professional Machin* e Learning Engineer</a><ul>
<li class="chapter" data-level="9.5.1" data-path="data-science.html"><a href="data-science.html#big-data-and-ml-fundamentals"><i class="fa fa-check"></i><b>9.5.1</b> Big Data and ML Fundamentals</a></li>
<li class="chapter" data-level="9.5.2" data-path="data-science.html"><a href="data-science.html#recommending-products-using-cloud-sql-and-spark"><i class="fa fa-check"></i><b>9.5.2</b> Recommending Products using Cloud SQL and Spark</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="data-science.html"><a href="data-science.html#kyndryl-data-science-roudmap"><i class="fa fa-check"></i><b>9.6</b> Kyndryl Data Science Roudmap</a><ul>
<li class="chapter" data-level="9.6.1" data-path="data-science.html"><a href="data-science.html#data-science--project-management-methodology---crisp-dm"><i class="fa fa-check"></i><b>9.6.1</b> Data Science- Project Management Methodology - CRISP-DM</a></li>
<li class="chapter" data-level="9.6.2" data-path="data-science.html"><a href="data-science.html#statistics-for-data-analysis-using-python"><i class="fa fa-check"></i><b>9.6.2</b> Statistics for Data Analysis Using Python</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Learning notes : Linux, Devops, entre outros</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="data-science" class="section level1 hasAnchor">
<h1><span class="header-section-number"># 9</span> Data Science<a href="data-science.html#data-science" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="datacamp-python-skills-for-data-science" class="section level2 hasAnchor">
<h2><span class="header-section-number">9.1</span> DataCamp Python Skills for Data Science<a href="data-science.html#datacamp-python-skills-for-data-science" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="introduction-to-python" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.1.1</span> Introduction to Python<a href="data-science.html#introduction-to-python" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="python-basic" class="section level4 hasAnchor">
<h4><span class="header-section-number">9.1.1.1</span> Python Basic<a href="data-science.html#python-basic" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Version 3.x - <a href="https://www.python.org/downloads">https://www.python.org/downloads</a></p>
<p>We can save the script with .py and use python as calculator or usa ipython or python shell</p>
<pre><code># Addition and subtraction
print(5 + 5)
print(5 - 5)

# Multiplication and division
print(3 * 5)
print(10 / 2)

# Exponentiation
print(4 ** 2)

# invest
print(100 * 7.1)

# Modulo
print(18 % 7)

# How much is your $100 worth after 7 years?
print(100*1.1**7)</code></pre>
<p><br></p>
<p><strong>Variable</strong></p>
<ul>
<li><p>Specific, case-sensitive</p></li>
<li><p><code>type(&lt;variable&gt;)</code> to check the type of variable</p></li>
<li><p>Types</p>
<ul>
<li>int - integer numbers</li>
<li>float - real numbers</li>
<li>bool - True , False</li>
<li>str - string, text</li>
</ul></li>
</ul>
<p><br></p>
<p><strong>Lists</strong></p>
<ul>
<li>[a,b,c, 1, True, 1.2 [a,b]]</li>
<li>Collection of values, contain any type</li>
<li>Slicing
<ul>
<li>First element index 0</li>
<li>-1 last element</li>
<li>Range [3:5] , last element not included [start : end(excluded)]</li>
<li>Subsetting list of list [][]</li>
</ul></li>
</ul>
<hr />
</div>
</div>
</div>
<div id="datacamp-r-skills-for-data-science" class="section level2 hasAnchor">
<h2><span class="header-section-number">9.2</span> DataCamp R Skills for Data Science<a href="data-science.html#datacamp-r-skills-for-data-science" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
</div>
<div id="azure-data-science-certification" class="section level2 hasAnchor">
<h2><span class="header-section-number">9.3</span> Azure Data Science Certification<a href="data-science.html#azure-data-science-certification" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
</div>
<div id="aws-data-science-certification" class="section level2 hasAnchor">
<h2><span class="header-section-number">9.4</span> AWS Data Science Certification<a href="data-science.html#aws-data-science-certification" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="demystifying-ai-ml-dl" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.4.1</span> Demystifying AI / ML / DL<a href="data-science.html#demystifying-ai-ml-dl" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>What is AI ?</strong></p>
<p>Ability to scan and interpret the physical devices, for that we need to provide info of real world</p>
<ul>
<li><p>Knowledge (<em>data</em>) + Software programs = decisions</p></li>
<li><p>Transfer human expertise to solve a specific problem (<em>model</em>)</p></li>
<li><p>Machine learning and Deep learning are subset of AI</p></li>
<li><p><strong>ML</strong> : Data -&gt; processing -&gt; Predictions</p>
<ul>
<li><p>Machine learning can do :</p>
<ul>
<li>Make predictions</li>
<li>Optimize utility functions</li>
<li>Extract hidden data structures</li>
<li>Classify data</li>
</ul></li>
</ul></li>
<li><p><strong>DL</strong></p>
<ul>
<li>Enable the machine define the features itself, for instance, you show the machine several samples of rectangle and machine will be able to extract the features and recognize a probably rectangle.</li>
</ul></li>
</ul>
<p><br></p>
<ul>
<li><p>How to Establish an Effective AI Strategy</p>
<ul>
<li>Fast computing environments</li>
<li>Data gathering from several sources, ubiquitous data</li>
<li>Advanced learning algorithms</li>
</ul></li>
</ul>
<p><em>The Flywheel of Data</em></p>
<p><img src="img/flywheel_of_data.png" width="90%" /></p>
<ul>
<li><strong>AI on AWS</strong></li>
</ul>
<p><img src="img/ai_on_aws.png" width="90%" /></p>
<p><strong>What is Machine Learning</strong></p>
<ul>
<li><p>Subset of AI</p></li>
<li><p>Process that takes data and use that to make predictinos and support decisions</p></li>
<li><p>Types of Machine Learning</p></li>
</ul>
<p><img src="img/types_of_ML_AWS.png" width="90%" /></p>
<p><strong>Suggestion</strong></p>
<p><em>Intro to ML video 1:</em></p>
<p>Complete sequence of videos <a href="https://www.youtube.com/watch?v=CzdWqFTmn0Y&amp;list=PLfYUBJiXbdtSyktd8A_x0JNd6lxDcZE96">here</a></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/CzdWqFTmn0Y" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope ; picture-in-picture">
</iframe>
<p><strong>What is Deep Learning</strong></p>
<ul>
<li>Deep Learning is a subset of Machine Learning</li>
<li>Use many layers of non-linear processing units, for feature extraction and transformation</li>
<li>Algorithms can be supervised and unsupervised</li>
</ul>
<p><img src="img/nn_aws_ml.png" width="90%" /></p>
<ul>
<li><p>Types of Neural Networks</p>
<ul>
<li>Feedforward</li>
<li>Recurrent</li>
</ul></li>
<li><p>AWS Deep Learning Based Managed Services</p>
<ul>
<li><p><strong>Amazon Lex</strong> : conversational engine</p></li>
<li><p><strong>Amazon Polly</strong> : lifelike speech</p></li>
<li><p><strong>Amazon Rekognition</strong> : Image analysis</p></li>
</ul></li>
<li><p>AWS Deep Learning AMI (<em>custom models</em>)</p>
<ul>
<li><p>AMI is pre-configured with : MXNet, TensorFlow, Microsoft Cognitive Engine, Caffe, Theano, Torch and Keras</p></li>
<li><p>Support auto-scaling cluster of GPU for large training</p></li>
</ul></li>
</ul>
<p><strong>Suggestion</strong></p>
<p><em>Intro to DL video 1:</em></p>
<p>Complete sequence of videos <a href="https://www.youtube.com/watch?v=_QUEXsHfsA0&amp;list=PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM">here</a></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/_QUEXsHfsA0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope ; picture-in-picture">
</iframe>
</div>
<div id="machine-learning-essentials-for-business-and-technical-decision-makers" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.4.2</span> Machine Learning Essentials for Business and Technical Decision Makers<a href="data-science.html#machine-learning-essentials-for-business-and-technical-decision-makers" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>What is Machine Learning(ML) ? </strong> : Process of training computers, using math and statistical processes, to find and recognize patterns in data.</p>
<p><strong>Iterative process</strong></p>
<p><img src="img/ml_process_aws.png" width="90%" /></p>
<p><strong>How Amazon uses ML in products ? </strong></p>
<ul>
<li>Browsing and purchasing data to provide recommendations</li>
<li>Use voice interactions with <code>Alexa</code> using NLP</li>
<li>Use ML to ship 1.6M packages per day</li>
</ul>
<p><strong>How is machine learning helping AWS customers?</strong></p>
<ul>
<li><p>Amazon Forecast</p></li>
<li><p>Amazon Fraud Detector</p></li>
<li><p>Amazon Personalize (<em>product recommendation,direct marketing</em>)</p></li>
<li><p>Amazon Polly (TTS - <em>text-to-speech</em>) uses advanced deep learning technologies to synthesize natural-sounding human speech</p></li>
<li><p>Amazon Transcribe (STT - <em>speech-to-text</em>)</p></li>
<li><p>Amazon SageMaker</p></li>
<li><p><a href="https://aws.amazon.com/machine-learning/?nc2=h_ql_prod_ml">Machine Learning on AWS</a></p></li>
</ul>
<p><br></p>
<p><strong>How does machine learning work?</strong></p>
<ul>
<li>What is AI ? : any system that is able to ingest human-level knowledge to automate and accelerate tasks performable by humans through natural intelligence.
<ul>
<li><p><em>Narrow AI</em> : where an AI imitates human intelligence in a single context (<strong>Todays AI</strong>)</p></li>
<li><p><em>General AI</em> : where an AI learns and behaves with intelligence across multiple contexts (<strong>Future AI</strong>)</p></li>
</ul></li>
</ul>
<p><strong>What kind of solutions can ML provide?</strong></p>
<ul>
<li><strong>Regression</strong> : Prediction a numerical value , <a href="https://aws.amazon.com/solutions/case-studies/zillow-zestimate/">Zillow case</a></li>
<li><strong>Classification</strong> : Predicting label, <a href="https://aws.amazon.com/machine-learning/customers/innovators/duolingo/">duolingo case</a></li>
<li><strong>Ranking</strong> : Ordering items to find most relevant , <a href="https://aws.amazon.com/solutions/case-studies/dominos-case-study/">Dominos case</a></li>
<li><strong>Recommendation</strong> : Finding relevant items based on past behavior <a href="https://aws.amazon.com/solutions/case-studies/hyatt-hotels-case-study/">Hyatt Hotels</a></li>
<li><strong>Clustering</strong> : Finding patterns in examples <a href="https://www.amazon.science/how-nasa-uses-aws-to-protect-life-and-infrastructure-on-earth">NASA</a></li>
<li><strong>Anomaly detection</strong> : Finding outliers from examples, <a href="https://aws.amazon.com/solutions/case-studies/fraud-dot-net/">Fraud.net cases</a></li>
</ul>
<p><img src="img/sk_guide_algo.png" width="90%" /></p>
<p><br></p>
<p><strong>What are some potential problems with machine learning ? </strong></p>
<ul>
<li>Ingestion of poor quality data</li>
<li>Explain complex models</li>
</ul>
</div>
<div id="machine-learning-for-business-leaders" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.4.3</span> Machine Learning for Business Leaders<a href="data-science.html#machine-learning-for-business-leaders" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>When is ML an option ?</strong></p>
<ul>
<li>If the problem is persistent</li>
<li>If the problem challenges progress or growth</li>
<li>If the solution needs to scale</li>
<li>If the problem requires personalization ir order to be solved</li>
</ul>
<p><strong>What Does a successfull ML solution require ? </strong></p>
<ul>
<li>People (<em>Data Scientist, Data Engineer, ML Scientist, Software Engineers, etc</em>)</li>
<li>Time</li>
<li>Cost</li>
</ul>
<p><strong>Ask the right questions to team</strong></p>
<ul>
<li>What are the made assumptions ?</li>
<li>What is your learning target (hipotesis)?</li>
<li>What type of ML problem is it ?</li>
<li>Why did you choose this algorithm ?</li>
<li>How will you evaluate the model performance ?</li>
<li>How confident are you that you can generalize the results ?</li>
</ul>
<p><strong>How to define and scope a ML Problem</strong></p>
<ul>
<li>What is the specific business problem ?</li>
<li>What is the current state solution ?</li>
<li>What are the current pain points ?</li>
<li>What is causing the pain points ?</li>
<li>What is the problems impact ?</li>
<li>How would the solution be used ?</li>
<li>What is out of scope ?</li>
<li>How do you define success (<em>success criteria</em>)?</li>
</ul>
<p><em>Input Gathering</em></p>
<ul>
<li>Do we have sufficient data ?</li>
<li>Is there labeled examples ?</li>
<li>If not , how difficult would it be to create/obtain ?</li>
<li>What are our features ?</li>
<li>What are going to be the most useful inputs ?</li>
<li>Where is the data ?</li>
<li>What is the data quality ?</li>
</ul>
<p><em>Output Definitions</em></p>
<ul>
<li>What business metric is defining success ?</li>
<li>What are the trade-offs ?</li>
<li>Are there existing baselines ?</li>
<li>If not, what is the simplest solutions ?</li>
<li>Is there any data validation need to green light the project ?</li>
<li>How important is runtime and performance ?</li>
</ul>
<p>With those inputs and outputs we can formulate the problem as a <strong>Learning Task</strong>, is this a classification or regression problem ? What are the risks ? etc </p>
<p><strong>When should you consider using machine learning to solve a problem ? </strong></p>
<ul>
<li>Use ML when software logic is too difficult to code</li>
<li>Use ML when the manual process is not cost effective</li>
<li>Use ML when there is ample training data</li>
<li>Use ML when the problems is formalizable as an ML Problem (<em>reduce to well known ML problem regression, classification, cluster</em>)</li>
</ul>
<p><strong>When is Machine Learning NOT a Good Solution?</strong></p>
<ul>
<li>No data</li>
<li>No Labels</li>
<li>Need to launch quickly</li>
<li>No tolerance for mistakes</li>
</ul>
<p><strong>When is Machine Learning is a Good Solution ?</strong></p>
<ul>
<li>Difficult to directly code a solution</li>
<li>Difficult to scale a code-based solution</li>
<li>Personalized output</li>
<li>Functions change over time</li>
</ul>
</div>
<div id="process-model-crisp-dm-on-the-aws-stack" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.4.4</span> Process Model : CRISP-DM on the AWS Stack<a href="data-science.html#process-model-crisp-dm-on-the-aws-stack" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Into</strong></p>
<blockquote>
<p>CRISP-DM Cross Industry Standard Process - Data Mining, excelent framework to build data science project</p>
</blockquote>
<p><img src="img/crisp-dm-aws.png" width="60%" /></p>
<p>There are 6 phases and the first (<em>Business Understanding</em>) one is the most important one, in that phase you going to understand the problem and know if this suitable for ML or not.</p>
<p><strong>Phase 1: BUSINESS UNDERSTANTING</strong></p>
<p>This phase there are 4 tasks :</p>
<ol style="list-style-type: decimal">
<li><p><em>Understating business requiriment</em> : Important to totally <strong>understand the customer needs</strong> and think on the <strong>questions from a business perspective</strong> that need to be answered (<em>areas and business that need to improve</em>) and convert that a problem that need to be solved or a problem that need to be answered, also <strong>high the critical features</strong> of projects (<em>people, resources, etc</em>)</p></li>
<li><p><em>Analyzing support information</em> : <strong>Collect information</strong> necessary based on the business question from task 1, make sure to <strong>list all the required resources and assumptions</strong>, analyze the risks, make a <strong>plan for contingencies</strong> and compare the <strong>costs and benefits</strong> for the project</p></li>
<li><p><em>Converting to a Data Mining problem</em>: Get the business question from task 2 and convert in machine learning objective <strong>(<em>classification ? ; regression ?; clustering ? </em>)</strong> problem and define a <strong>criteria for successful</strong></p></li>
<li><p><em>Preparing a preliminary plan</em>: That plan should describe the project and steps to achieve the goal:</p>
<ul>
<li>Timeline with number of stages and duration</li>
<li>Dependencies</li>
<li>Risks</li>
<li>Business and Data Mining Goals</li>
<li>Evaluation methods</li>
<li>Tools and techniques necessary for each stage</li>
</ul></li>
</ol>
<p><br></p>
<p><strong>Phase 2: DATA UNDERSTANTING</strong></p>
<p>This phase there are basically 3 tasks :</p>
<ol style="list-style-type: decimal">
<li><p><em>Data Collection</em> : Need to <strong>analyze which data should be be used</strong> for the project, detail the <strong>sources</strong> and <strong>steps to extract data</strong>, having the data analyze for additional requirements (<em>checking missing values, if data need to be encode or decode, if need to be normalized, check if are the specific fields that are more important to solve the problem ?</em>) and consider <strong>other data sources</strong> (<em>customer is an important resource because they know the domain knowledge</em>).</p></li>
<li><p><em>Data properties</em> : <strong>Describe the data</strong> (<em>Structured / Unstructured</em>), amount of data used and <strong>metadata properties</strong>, including the complexity of data relationships and key features, also include the <strong>basics statistics</strong> (<em>mean, median, etc</em>), check the correlation of the main attributes, we can use python, sql, R and reporting tools using graphs to <strong>update the assumptions is necessary</strong></p></li>
<li><p><em>Quality</em> : How many attributes contain <strong>errors</strong> ? , There are <strong>missing data</strong> ? Check the meaning of the attributes and complete the missing data, also check the <strong>inconsistencies</strong> and report all problems on this task and list the steps to solve this problem</p></li>
</ol>
<p>On AWS we can perform this task using <strong>Amazon Athena</strong>, <strong>Amazon QuickSight</strong> and <strong>AWS Glue</strong></p>
<ul>
<li><p><strong>Glue</strong> <em>Manage ETL service</em></p>
<ul>
<li>Step 1 : Build data catalog</li>
<li>Step 2 : Dev env to test and Generate and edit transformations</li>
<li>Step 3 : Schedule and run your jobs</li>
</ul></li>
<li><p><strong>Athena</strong> <em>interact query service to run SQL queries on Amazon S3</em></p>
<ul>
<li>Serveless where only pay for the queries</li>
<li>Integrated with quicksight</li>
<li>Support ANSI SQL operations and functions</li>
</ul></li>
<li><p><strong>QuickSight</strong></p>
<ul>
<li>Fast cloud powered BI service</li>
<li>We can scale</li>
<li>1/10th of the cost of traditional BI solutions</li>
<li>Secure and collaboration</li>
</ul></li>
</ul>
<p><strong>Phase 3 &amp; 4: DATA PREPARATION TASK &amp; MODELING</strong></p>
<p><strong>Phase 3</strong> consist in two tasks</p>
<ul>
<li><p><strong><em>Final dataset selection</em></strong> : Here we should analyze the size, record selection and data types, also include and exclude columns based on data understand phase</p></li>
<li><p><strong><em>Preparing the data</em></strong>:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Clean</strong> for quality</p>
<ul>
<li>Working on <strong>missing data</strong> : Dropping rows with missing values or adding a default value (<em>mean, median</em>) or work with imputation to add the missing data, we can also use statistical methods to calculate the value. It is also important to clean the corrupt data or variable noise</li>
</ul></li>
<li><p><strong>Transforming</strong> for the best performance of model</p>
<ul>
<li><strong>Derive additional</strong> attributes from the original (<em>Datatime to hour, month, day </em>), use <strong>one-hot encoding</strong> to convert the strings , also recommend to <strong>normalize</strong> the data</li>
</ul></li>
<li><p><strong>Merging</strong> all datasets in one final dataset</p>
<ul>
<li>Create the final dataset using joins and concatenations , recommend to revisit the Data Understanding phase to review the attributes</li>
</ul></li>
<li><p><strong>Formatting</strong> to properly work on model</p>
<ul>
<li>Reformatting the data types and attributes (covert variables), randomly shuffle the data and remove unicode if necessary</li>
</ul></li>
</ol></li>
</ul>
<p><strong>Phase 4</strong> Modeling</p>
<p><em>This phase work together with Data Preparation phase</em></p>
<p>Modeling have 3 steps:</p>
<ul>
<li><p><em>Model selection and creation</em> : Here we will <strong>select a model to address the ML problem</strong> (<em>Regression for numeric problems and Random forest for Classification</em>)</p></li>
<li><p><em>Model testing plan</em> : Before create the model we need to define <strong>how to test</strong> the model accuracy, split the data in Test and Training dataset (<strong>30/70</strong>), also there are other techniques, such as <strong>k-fold</strong>, for the model <strong>evaluation criterion</strong> we can use MSE, ROC, Confusion matrix, etc</p></li>
<li><p><em>Model parameter tuning/testing</em> : <strong>build the model</strong> , train the model and tweak the best performance (document the hiperparameters and reason), build multiple models with different parameters and report the findings</p></li>
</ul>
<p>Tools for Data Preparations and Modeling :</p>
<ul>
<li><p><strong>Amazon EMR + Spark</strong></p>
<ul>
<li>We can use EMR and the package <strong>Spark MLlib</strong> to create DataFrame based APIs for ML, using ipython notebooks, zepplin or R studio</li>
<li>Support <strong>Scala, Python, R, Java and SQL</strong></li>
<li>Cost savings : Leverage spot instance for the task nodes</li>
</ul></li>
<li><p><strong>Amazon EC2 + Deep Learning AMI</strong></p>
<ul>
<li>The two main EC2 base ML environments are <strong>R studio</strong> and <strong>AWS Deep Learning AMI</strong>, this one preinstalled with GPU and frameworks ( <em>MXNet, TensorFlow, Caffe2, Tourch, Keras, etc</em> ) , also include Anaconda Data Science platform with popular libraries like numpy, scikit-learn, etc</li>
</ul></li>
<li><p><a href="https://aws.amazon.com/blogs/big-data/running-r-on-aws/">To install R studio in EC2</a></p></li>
</ul>
<p><strong>Phase 5: EVALUATION</strong></p>
<p>In this phase we have two main tasks :</p>
<ol style="list-style-type: decimal">
<li><p>Evaluate how the model is performing related to business goals</p>
<ul>
<li><p>Dependens on :</p>
<ul>
<li>Accuracy of model or evaluation criteria on planning phase</li>
<li>Converte the assessments to business need (monetary cost)</li>
<li>Make a summary of results, ranking the models based on successfully criteria</li>
</ul></li>
</ul></li>
</ol>
<p><br></p>
<ol start="2" style="list-style-type: decimal">
<li><p>Make final decision to deploy or not</p>
<ul>
<li><p>Review the project and the assess the steps taken in each phase and perform quality assurance checks (<em>is the data available for future training, model performance is using the determinated data</em>)</p></li>
<li><p>If the process fail to deploy due the successfully criteria, analise the business goals and try different approache or update the business goals and try again</p></li>
</ul></li>
</ol>
<p><strong>Phase 6: DEPLOYMENT</strong></p>
<p>Tasks :</p>
<ol style="list-style-type: decimal">
<li><p>Planning deployment</p>
<ul>
<li>Runtime : Identity where it going to run (<em>EC2, EC2 Container Service, AWS Lambda</em>)</li>
<li>Application deployment : AWS Code deploy (<em>EC2</em>), AWS OpsWorks (<em>use chef</em>), AWS Elastic Beanstalk (<em>run the models on virtual servers</em>)</li>
</ul></li>
<li><p>Maintenance and monitoring</p>
<ul>
<li>Infrastructure deployment : AWS CloudFormation, AWS OpsWorks, AWS Elastic Beanstalk</li>
<li>Code Management : AWS CodeCommit, AWS CodePipeline (<em>CI/CD</em>) and AWS Elastic Beanstalk</li>
<li>Monitoring: Amazon CloudWatch, AWS Cloud Trail and AWS Elastic Beanstalk</li>
</ul></li>
<li><p>Final report</p>
<ul>
<li>Document all steps and highlight processes used</li>
<li>Goals met the project goals ?</li>
<li>Detail the findings</li>
<li>Identify and explain the model used and reason behind using the model</li>
<li>Identify the customer groups to target using this model</li>
</ul></li>
<li><p>Project review</p>
<ul>
<li>Outcomes of the project : Summarize results and write thorough documentation and generalize the whole process to make it useful for the next iteration</li>
</ul></li>
</ol>
<ul>
<li>Task : create EC2 install packages and access from browser ssh <code>&lt;connection&gt; -L localhost:8888:localhost:8888</code></li>
</ul>
<p><strong>Setup EC2 to run notebook</strong></p>
<ol style="list-style-type: decimal">
<li><p>Create EC2 instance</p></li>
<li><p>Connect to instance via ssh</p></li>
<li><p>Install python</p></li>
</ol>
<pre><code>sudo yum update
sudo yum install python</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Create a virtual environment and activate</li>
</ol>
<pre><code>python3 -m venv basic
source ~/basic/bin/activate</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Install basic database science packages</li>
</ol>
<pre><code>pip install pandas numpy matplotlib seaborn scikit-learn statsmodels jupyter jupyterlab</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>Configure the jupyter password</li>
</ol>
<pre><code>jupyter notebook --generate-config
jupyter notebook password</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Open a tunnel and Start jupyter notebook</li>
</ol>
<pre><code>ssh -i &quot;&lt;key&gt;.pem&quot; ec2-user@&lt;ec2 machine&gt;m -f -N -L 8888:localhost:8888

jupyter notebook --no browser
</code></pre>
<ol start="8" style="list-style-type: decimal">
<li>Access the notebook from browser <a href="http://localhost:8888/" class="uri">http://localhost:8888/</a></li>
</ol>
</div>
<div id="machine-learning-terminology-and-process" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.4.5</span> Machine Learning Terminology and Process<a href="data-science.html#machine-learning-terminology-and-process" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>End to End Machine Learning Process and common ML Terminoly</p>
</blockquote>
<p><strong>ML Terminology</strong></p>
<ul>
<li><strong>Training</strong> : How ML use historical dataset to build prediction algorithm(<em>model</em>)</li>
<li><strong>Model</strong> : Core of ML process, enable the machine to determine an output variable(<em>prediction</em>) from an input variable</li>
<li><strong>Prediction</strong> (<em>inference</em>): Best estimate of a given input would be</li>
</ul>
<p><strong>Process</strong></p>
<ol style="list-style-type: decimal">
<li><p>The Business Problem</p></li>
<li><p>The Machine Learning framing (<em>Transform the business problem into ML problem</em>), define the type of ML</p></li>
<li><p>Data Collection and Integration (<em>Collect data from multiple sources</em>)</p></li>
<li><p>Data Preparation (<em>steps before ML algorithm use the data</em>)</p>
<ul>
<li>Data Cleaning</li>
<li>Impute missing values (<em>new variable indication the missing value, remove rows, imputation(mean, media, other)</em>)</li>
<li>Shuffle training data (<em>stract a fraction of data for training</em>) <code>train_data = train_data.sample(frac = 1)</code></li>
<li>Test-validation-train split (<em>20% test , 10% validation, 70% train</em>)</li>
<li>Cross validation (<em>Validation(30/70 or 20/10/70), Leave-one-out, k-fold</em>)</li>
</ul></li>
<li><p>Data Visualization and Analysis (<em>better understand of data</em>)</p>
<ul>
<li>Statistics</li>
<li>Scatter-plots</li>
<li>Histograms</li>
</ul></li>
<li><p>Feature Engineering</p>
<ul>
<li><p>Binning : To introduce non-linearity into linear models</p></li>
<li><p>Combine features together to create complex feature</p></li>
<li><p>Take the log of feature or polinomial power of target</p></li>
<li><p>Text-Features :</p>
<ul>
<li>Stop-words removal / Steamming</li>
<li>Lowercasing, punctuation removal</li>
<li>Cutting off very high/low percentiles</li>
<li>TF-IDF normalization</li>
</ul></li>
<li><p>Web-page features</p>
<ul>
<li>multiple fields of text : URL, title, frames, body</li>
<li>relative style and position</li>
</ul></li>
</ul></li>
<li><p>Model training</p></li>
</ol>
<ul>
<li><p><strong>Loss Function</strong> (<em>How far predictions are from objective</em>)</p>
<ul>
<li>Square : regression, classification</li>
<li>Hinge : classification only (<em>robust to outliers</em>)</li>
<li>Logistic : Classification only (<em>better for skewed class distribution</em>)</li>
</ul></li>
<li><p><strong>Regularization</strong></p>
<ul>
<li>Prevent overfitting by constraining weights to be small</li>
</ul></li>
<li><p><strong>Learning Parameters</strong> (<em>decay rate</em>) <em>How fast the algorithm learn</em></p>
<ul>
<li>Decaying too aggressively - algorithm never reaches optimum</li>
<li>Decaying too slowly - algorithm bounces around, never converge to optimum</li>
</ul></li>
</ul>
<ol start="8" style="list-style-type: decimal">
<li>Model Evaluation</li>
</ol>
<ul>
<li><p><strong>Overfitting &amp; Underfitting</strong></p>
<ul>
<li>Dont fit data to obtain maximum accuracy</li>
</ul>
<p><img src="img/overfitting_underfitting_aws.png" width="90%" /></p>
<ul>
<li><p><strong>Bias-Variance Tradeoff</strong></p>
<ul>
<li>Bias : Difference between average model predictions and true target values</li>
<li>Variance : Variation in predictions across different training data samples</li>
</ul></li>
</ul>
<p><img src="img/bias_variance_trade_off_aws.png" width="90%" /></p>
<ul>
<li><p><strong>Evaluation Metrics</strong></p>
<ul>
<li><p>Regression :</p>
<ul>
<li>RMSE - Root Meam Squared Error</li>
<li>MAPE - Mean Absolute Percent Error</li>
<li>R^2 - How much better is the model compared to just pick the best constrant (R^2 = 1 - (model MSE / variance))</li>
</ul></li>
<li><p>Classification :</p>
<ul>
<li><p>Confusion Matrix</p></li>
<li><p>ROC Curve</p></li>
<li><p>Precision-Recall</p>
<ul>
<li><strong>Precision</strong> : How correct we are when we what to predict be positive</li>
<li><strong>Recall</strong> (<em>Sensitivity</em>) : Fraction of negative that was wrongly predicted</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p><img src="img/confusion_matrix_prec_recal_aws.png" width="90%" /></p></li>
</ul>
<ol start="9" style="list-style-type: decimal">
<li>Business Goal Evaluation</li>
</ol>
<ul>
<li>Evaluate how the model is performing related to <strong>business goals</strong></li>
<li>Make the final decision to deploy or not</li>
</ul>
<p>Evaluation depends on:</p>
<ul>
<li>Accuracy</li>
<li>Model generalization on unseen/unknown data</li>
<li>Business success criteria</li>
</ul>
<p>If we need more data or have more data we can add data (<strong>Data Augmentation</strong>) or feature (<strong>Feature Augmentation</strong>)</p>
<ul>
<li>Prediction : The production data MUST have the same distribution as the training data</li>
</ul>
</div>
<div id="data-engineering" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.4.6</span> Data Engineering<a href="data-science.html#data-engineering" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>S3</strong></p>
<ul>
<li>Buckets must have a <em>global unique name</em></li>
<li>Objects (file) have a key. The key is the FULL path : <code>&lt;my_bucket&gt;/my_folder/my_file.txt</code></li>
<li>Max 5TB</li>
<li>Backbone for ML services</li>
<li>Perfect use case for <strong>Data Lake</strong>, with infinite size , 99.999999999% durability across multiple AZ and 99.99% availability (<em>not available 53 min a year</em>)</li>
<li>Obejct storage supports any file format (<em>CSV, JSON, Parquet, ORC, Avro, Protobuf</em>)</li>
<li>We can partition the data by date, by product or any strategy we would like, some tools perform this task forus (Glue and Kinises)</li>
</ul>
<p><br></p>
<p><em><a href="https://aws.amazon.com/s3/storage-classes/">Amazon S3 Storage Classes</a></em>:</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Classes</th>
<th>Details</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>S3 Standard - General purpose</td>
<td>* 99.99% availability (53min a year not available)<br>* Used for frequently accessed data<br>* Low latency and high throughput<br>* Sustain 2 concurrent failures</td>
<td>Big data analytics, mobile and gaming applications</td>
</tr>
<tr class="even">
<td>S3 Standard-Infrequent Access IA</td>
<td>* For data that is less frequently accessed, but requires rapid access when needed<br>* Low cost than S3 standard, cost on retrieval<br>* 99.9% availability <br></td>
<td>Used for Disaster recovery</td>
</tr>
<tr class="odd">
<td>S3 One Zone-Infrequent access</td>
<td>* High durability 99.999999999% in a single AZ, data lost when AZ distroied<br>* 99.5% availability</td>
<td>Storing secondary backup copies of on-prem data, or data you can recriate</td>
</tr>
<tr class="even">
<td>S3 Glacier Instant Retrieval<br><br>Low cost for archive/backup</td>
<td><strong>Instant retrieval</strong> : ms retrieval , min storage duration 90 days<br><br><strong>Flexible Retrieval</strong> : Expedite 1 to 5min , Standard 3 to 5 hours, min duration 90 days<br><br><strong>Deep Archive</strong> : Standard 12hrs, bulk 48hrs, min duration 180 days, for long archive</td>
<td></td>
</tr>
<tr class="odd">
<td>S3 Intelligent Tiering</td>
<td>* Small monthly monitoring and auto-tiering fee<br>* Move objects automatically between Tiers based on usage<br>* No retrieval charge<br><br>* <strong>Frequent Access</strong> : default<br>* <strong>Infrequent Access</strong> &gt; 30 days<br><br>* <strong>Archive Instant Access</strong> &gt; 90 days<br>* <strong>Archive Access</strong> 90 to 700+ days<br>* <strong>Deep Archive Access</strong> 180 to 700+ days<br><br></td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li><p>We can move files between storage classes manually or via configuration using <strong>Lifecycle Rules</strong></p></li>
<li><p>Security : <em>Encryption for objects</em></p>
<ul>
<li><strong>SSE-S3</strong> : encrypt using keys managed by AWS</li>
<li><strong>SSE-KMS</strong> : use Key Management Service (<em>Customer Master Key</em>)</li>
<li><strong>SSE-C</strong> : when we want to manage the keys</li>
<li><strong>Client Side Encryption</strong></li>
</ul></li>
</ul>
<p><em>On ML , <strong>SSE-S3</strong> and <strong>SSE-KMS</strong> will be most likely be used</em>
<em>SS3 means Service-side-encryption</em></p>
<ul>
<li><p>S3 Bucket policies : We can use the policies to grant access (<em>including Cross Account</em>) to bucket or force objects to be encrypted on upload</p>
<ul>
<li>Today we can use the <strong>default encryption</strong> option on S3 and every document sent to bucket will be encrypted by default</li>
</ul></li>
</ul>
<p><br></p>
<p><strong>AWS Kinesis</strong></p>
<p><strong>Kinesis</strong> is a managed alternative to Apache Kafka, it is used to <em>real-time</em> streaming process of big data, used for application logs, metrics, IoT, clickstreams and data replicated on 3 AZs</p>
<ul>
<li><p>Services :</p>
<ul>
<li><p><a href="https://aws.amazon.com/kinesis/data-streams/">Kinesis Data Streams</a> : low latency streaming ingest at scale</p>
<ul>
<li>Stream are divided into Shards/Partitions and by default data retention is 24hrs, multiple appls can use the same stream and once data is inserted it cannot be deleted (<strong>immutability</strong>)</li>
<li>It is for <strong>real-time</strong></li>
</ul></li>
</ul>
<p><img src="img/kinesis_stram_overview.png" width="80%" /></p>
<ul>
<li><p><a href="https://aws.amazon.com/kinesis/data-analytics/">Kinesis Data Analytics</a>: real-time analytics on streams using SQL</p>
<ul>
<li><p>Data Analytics will take data from Firehose or Data Streams, perform modifications using SQL and send it to analytic tools</p></li>
<li><p>Used to <strong>streaming ETL</strong>, continues metric and reponsive analytics (<em>filtering</em>)</p></li>
<li><p>Machine Learning on Kinesis Data Analytics (<em>two algorithms</em>)</p>
<ul>
<li><strong>RANDOM_CUT_FOREST</strong> (Used for <strong>anomaly detection</strong> on numeric columns, use recent history to compute model)</li>
<li><strong>HOTSPOTS</strong> (locate and return information about dense regions)</li>
</ul></li>
</ul></li>
</ul>
<p><img src="img/kinesis_data_analytics_aws.png" width="80%" /></p>
<ul>
<li><p><a href="https://aws.amazon.com/kinesis/data-firehose/">Kinesis Firehose</a>: load stream into S3, Redshift, ElasticSearch and splunk</p>
<ul>
<li>To store data in two target destination, it reads data up to 1MB, can be transformed by lambada function and write in batches into <strong>S3, RedShift, ElasticSearch</strong>, custom destionation or 3rd party (splunk, mongo, etc)</li>
<li>It is <strong>near real-time</strong> to ingest massive data, auto-scale, supporting many formats (csv, json, orc)</li>
</ul></li>
</ul>
<p><img src="img/kinesis_firehose_aws.png" width="80%" /></p>
<ul>
<li><p><a href="https://aws.amazon.com/pt/kinesis/video-streams/?amazon-kinesis-video-streams-resources-blog.sort-by=item.additionalFields.createdDate&amp;amazon-kinesis-video-streams-resources-blog.sort-order=desc">Kinesis video Stream</a>: stream video in real-time</p>
<ul>
<li>real-time video stream to create ML applications</li>
</ul></li>
</ul>
<p><img src="img/kinesis_video_aws.png" width="80%" /></p></li>
</ul>
<p><br></p>
<p><strong>GLUE DATA CATALOG</strong></p>
<p><a href="https://docs.aws.amazon.com/glue/index.html">GLUE Documentation</a></p>
<blockquote>
<p>Metadata repository for all tables</p>
</blockquote>
<ul>
<li>Automated schema inference</li>
<li>Schema visioned</li>
<li>Integration with Athena or RedShift (<em>schema &amp; data discovery</em>)</li>
<li>Glue Crawlers can help build the <strong>Data Catalog</strong></li>
</ul>
<p><strong>GLUE DATA CRAWLERS</strong></p>
<ul>
<li>Go through the data to infer schema and partitions, works in JSON,CSV and PARQUET</li>
<li>Will extract partition based on how S3 is organized</li>
</ul>
<p><strong>GLUE ETL</strong></p>
<ul>
<li><strong>Transform data</strong>, clean, modify (<em>Join, filter, dropfields, map</em>), generate code in python or spark and the target can be S3, JDBC, RDS, RedShift or Glue Catalog</li>
<li>ML Transformation : <strong>FindMatches ML</strong> identify duplicated or matching records in database</li>
<li>Jobs run on Spark Platform</li>
<li>Formats (csv, json, avro, parquet, orc and xml)</li>
<li>Also can use any apache spark transformatino (like k-means)</li>
</ul>
<p><br></p>
<p><strong>DATA STORE IN MACHINE LEARNING</strong></p>
<ul>
<li><strong>RedShift</strong> : Data warehouse, OLAP processing</li>
<li><strong>RDS, Aurora</strong> : Relation store OLTP</li>
<li><strong>DynamoDB</strong> : NoSQL data store</li>
<li><strong>S3</strong>: Object store, serveless</li>
<li><strong>OpenSearch</strong> (previously Elastic Search) : Indexing data</li>
<li><strong>ElastiCache</strong> : Caching mechanism</li>
</ul>
<p><br></p>
<p><strong><a href="https://aws.amazon.com/datapipeline/">AWS DATA PIPELINE</a></strong></p>
<p>Service to move data from one place to another (S3, RDS, DynamoDB,Redshift, EMR), <strong>ETL service</strong> where we can manage the task dependencies, retry and notifies on failure</p>
<p><em>What is the difference between GLUE and DATA PIPELINE ? </em></p>
<ul>
<li>Glue is Apache Spark focus , run Scala or Python jobs</li>
<li>Data Pipeline is an orchestration service where we have more control over the environment, compute resources and code and allow us access EC2 or EMR</li>
</ul>
<p><br></p>
<p><strong><a href="https://aws.amazon.com/batch/">AWS BATCH</a></strong></p>
<p>AWS Batch run jobs as Docker images, no need to manage cluster, fully <strong>serveless</strong> and we can schedule batch jobs using <strong>Cloud Watch Events</strong> or Orchestrate batch jobs using <strong>AWS Step Functions</strong></p>
<p><br></p>
<p><strong><a href="https://aws.amazon.com/pt/dms/">DMS DATABASE MIGRATION SERVICE</a></strong></p>
<p>Quickly and securely way to migrate databases to AWS, it supports Oracle to Oracle or MSSQL to Aurora, we can use continuous Data Replication using CDC and it the replication must be performed EC2 instance</p>
<p><br></p>
<p><strong><a href="https://aws.amazon.com/step-functions/">AWS Step Functions</a></strong></p>
<p>Step Functions is used to Orchestrate and design workflows</p>
<ul>
<li><a href="https://docs.aws.amazon.com/step-functions/latest/dg/sample-train-model.html">Train a Machine Learning Model</a></li>
</ul>
<p><br></p>
<hr />
<hr />
</div>
<div id="exploratory-data-analysis" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.4.7</span> Exploratory Data Analysis<a href="data-science.html#exploratory-data-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>PANDAS</strong></p>
<ul>
<li><p>Data Frames : Similar table structure</p></li>
<li><p>Series : 1D structure</p></li>
<li><p>Numpy : arrays and math</p>
<ul>
<li><a href="https://jovian.ai/brunodeabreu/100-numpy-exercises">100-numpy-exercises</a></li>
<li><a href="https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_hints_with_solutions.md">100-numpy-exercises - solutions</a></li>
</ul></li>
</ul>
<p><strong><a href="https://matplotlib.org/">MATPLOTLIB</a></strong></p>
<ul>
<li><p>Data Visualization</p>
<ul>
<li>Boxplot</li>
</ul>
<p><img src="img/boxplot_aws.png" width="90%" /></p>
<ul>
<li><a href="https://matplotlib.org/stable/gallery/statistics/hist.html">Histogram</a></li>
</ul>
<p><img src="img/hist_aws.png" width="90%" /></p></li>
<li><p><a href="https://seaborn.pydata.org/">Seaborn</a> : Python data visualization library based on matplotlib</p>
<ul>
<li><a href="https://seaborn.pydata.org/tutorial/relational.html">Visualizing statistical relationships</a></li>
<li><a href="https://seaborn.pydata.org/tutorial/distributions.html">Visualizing distributions of data</a></li>
<li><a href="https://seaborn.pydata.org/tutorial/categorical.html">Plotting with categorical data</a></li>
<li><a href="https://seaborn.pydata.org/tutorial/regression.html">Visualizing regression models</a></li>
</ul></li>
</ul>
<p><strong><a href="https://scikit-learn.org/stable/">Scikit_learn</a></strong></p>
<ul>
<li><a href="https://jupyter.org/">Jupyter notebooks</a></li>
</ul>
<p><strong>Type of Data</strong></p>
<ul>
<li>Numerical (<em>discrete</em> 5 , 20 <strong>or</strong> <em>continuous</em> 2.56, 545.67)</li>
<li>Categorical (<em>qualitative</em> Gender)</li>
<li>Ordinal (<em>Categorical with math meaning</em> Ranking)</li>
</ul>
<p><strong>Data Distribution</strong></p>
<ul>
<li><strong>Normal</strong></li>
</ul>
<p><img src="img/normal_dist_aws_course.png" width="90%" /></p>
<ul>
<li><p><strong>Probability Mass Function</strong></p>
<ul>
<li>Working with <strong>Discrete data</strong>, visualize the probability of discrete data occur</li>
</ul>
<p><img src="img/pmf_Aws.png" width="90%" /></p>
<ul>
<li><p>Poisson Distribution</p>
<ul>
<li>Example of probability mass function, series of events (success or failure)</li>
</ul>
<p><img src="img/poisson_dist_aws.png" width="90%" /></p></li>
</ul></li>
<li><p><strong>Binomial Distribution</strong></p>
<ul>
<li><p>Work with <strong>discrete data</strong></p>
<p><img src="img/binomial_dist_Aws.png" width="90%" /></p></li>
</ul></li>
</ul>
<p><strong>Time Series</strong></p>
<ul>
<li>Trends</li>
<li>Seasonality</li>
</ul>
<p><img src="img/trends_seasonality_aws.png" width="90%" /></p>
<ul>
<li>Seasonality + Trends + Noise = Time series</li>
</ul>
<p><strong>Amazon Athena</strong></p>
<blockquote>
<p>Serveless interactive queries of S2 data lake</p>
</blockquote>
<ul>
<li>Presto under the hood</li>
<li>Serverless</li>
<li>Supports (<em>CSV, JSON, ORC, PARQUET, AVRO</em>)</li>
<li>Pay-as-you-go</li>
<li>Save money using columnar formats (ORC, Parquet)</li>
</ul>
<p><strong>Amazon QuickSight</strong></p>
<blockquote>
<p>Business analytics and visualizations in the cloud</p>
</blockquote>
<ul>
<li>Build visualizations</li>
<li>Perform ad-hoc analysis</li>
<li>Serveless</li>
<li>Data Sources : RedShift, Aurora / RDS, EC2, Athena, S3</li>
<li><strong>SPICE</strong> : In-memory calculation makes QuickSight fast</li>
<li>ML Insights : Anomaly detection, Forecasting, Auto-narratives</li>
</ul>
<p><strong>Amazon EMR <em>Elastic MapReduce</em></strong></p>
<ul>
<li>Managed Hadoop framework on EC2</li>
<li>Includes Spark , HBase, Presto, Flink, hive and more</li>
<li>EMR Notebooks</li>
</ul>
<p><img src="img/emr_cluster_aws.png" width="90%" />
* <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark.html">Spark</a> Components that runs on top of <em>spark core</em></p>
<pre><code>* Spark Streaming
* Spark SQL
* Graph X
* MLLib

  * Classification : Logistic regression, naive bayes
  * Regression
  * Decision trees
  * Recommendation ALS
  * Cluster K-means
  * LDA (Topic modeling)
  * ML Workflow utilities (_pipeline, feature transformation, etc_)
  * PCA, SVD, statistics, others 
  


&lt;img src=&quot;img/chossing_EMR_Types.png&quot; width=&quot;90%&quot; /&gt;</code></pre>
<p><strong>Feature Engineering</strong></p>
<blockquote>
<p>Applied machine learning is basically feature engineering - Andrew Ng</p>
</blockquote>
<ul>
<li>Which features should I use ?</li>
<li>Do I need to transform these feature ?</li>
<li>How do I handle missing data ?</li>
<li>Should I create new feature ? Transform ? Normalize ?</li>
</ul>
<p><strong>Imputing Missing Data</strong></p>
<ul>
<li><p>Replace by mean ? median ?</p></li>
<li><p>Works on column level</p></li>
<li><p>Cannot use on categorical features</p></li>
<li><p>If not many rows and drop does not bias the data, maybe reasonable</p></li>
<li><p>Use Machine Learning</p>
<ul>
<li>KNN , average of group of features</li>
<li>Deep Learning, build ML to impute the data, works well for categorical data</li>
<li>Regression (<em>MICE</em>)</li>
</ul></li>
<li><p><strong>Get more data</strong></p></li>
</ul>
<p><strong>Unbalanced Data</strong></p>
<blockquote>
<p>Large discrepancy between positive and negative cases</p>
</blockquote>
<ul>
<li><strong>Oversampling</strong> : Duplicate samples from the minority class</li>
<li><strong>Undersampling</strong> : Instead of creating more positive samples, remove negative ones, <strong>remove data is not the right answer</strong></li>
<li><strong>SMOTE</strong> : <em><strong>S</strong>ynthetic <strong>M</strong>inority <strong>O</strong>ver-sampling <strong>TE</strong>chnique</em> generate new samples using nearest neighbors</li>
</ul>
<p><strong>Outliers</strong></p>
<ul>
<li><p>We can use Stardard deviation to identify outliers</p></li>
<li><p>AWS Random Cut Forest : outlier detection</p>
<p><img src="img/outliers_sample_aws.png" width="90%" /></p></li>
</ul>
<p><strong>Binning</strong></p>
<ul>
<li>Bucket observations together based on ranges of values</li>
<li>Transform numeric data to ordinal data</li>
</ul>
<p><strong>Encoding</strong></p>
<ul>
<li><p>Transform data into some new representation</p></li>
<li><p>One-Hot encoding</p></li>
<li><p><strong>Scalling / Normalization</strong></p>
<ul>
<li>Some models prefer feature data to be normally distributed</li>
<li>Scikit learn <em>MinMaxScaler</em></li>
</ul></li>
</ul>
<p><strong>Amazon SageMaker Ground Truth and Label Generation</strong></p>
<ul>
<li>Ground Truth creates its own model as images are labeled by people</li>
</ul>
<hr />
</div>
</div>
<div id="gcp---professional-machin-e-learning-engineer" class="section level2 hasAnchor">
<h2><span class="header-section-number">9.5</span> GCP - Professional Machin* e Learning Engineer<a href="data-science.html#gcp---professional-machin-e-learning-engineer" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="big-data-and-ml-fundamentals" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.5.1</span> Big Data and ML Fundamentals<a href="data-science.html#big-data-and-ml-fundamentals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Compute power</p>
<ul>
<li>We can easy create a server, execute the job, pause or delete the server</li>
</ul></li>
<li><p>Storage</p>
<ul>
<li><p>Big Data and Machine Learning are on top of <strong>Compute power</strong>, <strong>storage</strong> and <strong>Networking</strong> that are on top of <strong>security</strong></p></li>
<li><p>To create a storage bucket from UI is very simple by command line we can</p></li>
</ul></li>
</ul>
<pre><code>gsutil mb -p [PROJECT_NAME] -c [STORAGE_CLASS] -l [BUCKET_LOCATTION] gs://[BUCKET_NAME]/</code></pre>
<ul>
<li>Types of Storage</li>
</ul>
<p><img src="img/gcp_storage_types.png" width="60%" /></p>
<ul>
<li><p>Networking</p>
<ul>
<li>GCP datacenter are interconnected</li>
<li>Every machine can talk with each other with 10GBps</li>
</ul></li>
<li><p>Security</p>
<ul>
<li>Communication to GCP are encrypted in transit</li>
<li>Stored data are encrypted</li>
<li>BigQuery data are encrypted</li>
</ul></li>
</ul>
<p><img src="img/gcp_security_stack.png" width="60%" /></p>
<ul>
<li>GCP Offers</li>
</ul>
<p><img src="img/gcp_offfers.png" width="60%" /></p>
</div>
<div id="recommending-products-using-cloud-sql-and-spark" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.5.2</span> Recommending Products using Cloud SQL and Spark<a href="data-science.html#recommending-products-using-cloud-sql-and-spark" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="img/database_options_on_GCP.png" width="60%" /></p>
<p><img src="img/if_your_data_is.png" width="60%" /></p>
<ul>
<li>Cloud SQL : Google managed RDBMS Mysql</li>
</ul>
<hr />
</div>
</div>
<div id="kyndryl-data-science-roudmap" class="section level2 hasAnchor">
<h2><span class="header-section-number">9.6</span> Kyndryl Data Science Roudmap<a href="data-science.html#kyndryl-data-science-roudmap" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="data-science--project-management-methodology---crisp-dm" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.6.1</span> Data Science- Project Management Methodology - CRISP-DM<a href="data-science.html#data-science--project-management-methodology---crisp-dm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="kdd" class="section level4 hasAnchor">
<h4><span class="header-section-number">9.6.1.1</span> KDD<a href="data-science.html#kdd" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li><strong>Select</strong></li>
</ol>
<ul>
<li>Interpret the data</li>
<li>Select data relevant to analysis</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><strong>Preprocessing</strong></li>
</ol>
<ul>
<li>Outliers</li>
<li>Missing Values</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><strong>Transform</strong></li>
</ol>
<ul>
<li>Useful features</li>
<li>Smoothing (- binning - cluster)</li>
<li>Aggregation (- Weekly - month)</li>
<li>Normalization</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li><strong>Data Mining</strong></li>
</ol>
<ul>
<li>Explore</li>
<li>Graph</li>
<li>Predict</li>
<li>Models</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li><strong>Evaluating</strong></li>
</ol>
<ul>
<li>Check</li>
<li>Evaluate the results</li>
<li>Analysis</li>
</ul>
</div>
<div id="semma" class="section level4 hasAnchor">
<h4><span class="header-section-number">9.6.1.2</span> SEMMA<a href="data-science.html#semma" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>S</strong>ample : Subset of data (train, test validation)</p>
<p><strong>E</strong>xplore: Understand the data</p>
<p><strong>M</strong>:odify: Clean, feature engineering</p>
<p><strong>M</strong>odel: data mining, modeling</p>
<p><strong>A</strong>ssess: Model performance</p>
</div>
<div id="crisp-dm" class="section level4 hasAnchor">
<h4><span class="header-section-number">9.6.1.3</span> CRISP-DM<a href="data-science.html#crisp-dm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>Business Understand</li>
<li>Data Understand</li>
<li>Data Preparation</li>
<li>Modeling</li>
<li>Evaluation</li>
<li>Deploy</li>
</ol>
<div id="business-understand-initial-plan" class="section level5 hasAnchor">
<h5><span class="header-section-number">9.6.1.3.1</span> 1. Business Understand <em>initial plan</em><a href="data-science.html#business-understand-initial-plan" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Steps:</p>
<ol style="list-style-type: decimal">
<li><strong>Define Business Problem</strong> : Define the objective, the analitical problem, the expectations, success criteria, pain points</li>
<li><strong>Assess and Analyze Scenarios </strong></li>
<li><strong>Define Data Mining Problem</strong></li>
<li><strong>Project plan</strong> : Deliverable (timeline, costs, success criteria, assumptions, constraints, etc)</li>
</ol>
</div>
<div id="data-understand" class="section level5 hasAnchor">
<h5><span class="header-section-number">9.6.1.3.2</span> 2. Data Understand<a href="data-science.html#data-understand" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ol style="list-style-type: decimal">
<li><p><strong>Data Collection</strong> : Primary data source (survery, experiments) or secondary data source (ERP, CRM, database)</p></li>
<li><p><strong>Data Preparation / Description</strong></p></li>
</ol>
<ul>
<li>Quantitative (count, continuous ) vs Qualitative (categorical)</li>
<li>Balance vs Imbalance (one class less than 30% = Imbalance)</li>
<li>Structure (tabular) vs Unstructured(video, img, audio, text) vs Semi-structure</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><strong>Exploration - Data Analysis </strong></li>
</ol>
<ul>
<li><strong>Inferencial stats</strong>
<ul>
<li>Sampling - Balacing vs Imbalancing
<ul>
<li>Balancing : random sampling, sampling</li>
<li>Imbalancing: stratified sampling, K-fold, smote, msmote, leve-one-out</li>
</ul></li>
</ul></li>
<li><strong>Descriptive stats</strong>
<ul>
<li>Meam , media, mode</li>
<li>variance, std, range</li>
<li>skewness</li>
<li>kurtoses</li>
</ul></li>
<li><strong>Graphical </strong>
<ul>
<li>Univariant
<ul>
<li>Boxplot - Outliers, shape of distribution</li>
<li>Histogram - Shape, outliers</li>
<li>QQ Plot
<em>check train and test dataset if they are in the same distribution</em></li>
</ul></li>
<li>Bivariant
<ul>
<li>Scatter : correlation, coeficient (+1, -1) , strong (r &gt; 0.85 ) weak (r &lt; 0.4), cluster, linear</li>
</ul></li>
</ul></li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li><strong>Data Quality Analysis</strong></li>
</ol>
<ul>
<li>Idenfity outliers, missing values</li>
<li>Levels of granularity</li>
<li>Inconsistence</li>
<li>Wrong data errors</li>
<li>Meta info</li>
</ul>
</div>
<div id="data-preparation" class="section level5 hasAnchor">
<h5><span class="header-section-number">9.6.1.3.3</span> 3. Data Preparation<a href="data-science.html#data-preparation" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>In this step we clean, curate, wrangle and prepare the data</p>
<ul>
<li><p><strong>Outliers</strong> : 3R Techniques (Rectify, Remove, Retain)</p></li>
<li><p><strong>Missing Data</strong>: Imputation (mean, median, mode, regression, knn, etc)</p></li>
<li><p><strong>Data Transform</strong> : Log, exp, boxcox, etc, done when data are non-normal</p></li>
<li><p><strong>Data Normalization / Standartization</strong></p>
<ul>
<li>Normalization (mean = 0 , std =1 )</li>
<li>Standardization (min = 0 , max = 1) - MinMaxScaller</li>
</ul></li>
<li><p>Discretization, Binning, <strong>Grouping</strong></p></li>
<li><p>Dummy variable - <strong>OneHotEncoding</strong></p></li>
<li><p><strong>Apply domain knowledge to generate more features</strong></p></li>
</ul>
</div>
<div id="modeling" class="section level5 hasAnchor">
<h5><span class="header-section-number">9.6.1.3.4</span> 4. Modeling<a href="data-science.html#modeling" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li><p>Select model techniques</p></li>
<li><p>Model building</p></li>
<li><p>Model evaluation and tuning</p></li>
<li><p>Model Assessment</p></li>
<li><p><strong>Supervised Learning</strong></p>
<ul>
<li>Predict Y based on X</li>
<li>Categorical (2 class or multiclass)</li>
<li>numerical - Prediction</li>
<li>User preference - Recommendation</li>
<li>Relevance - Retrival</li>
</ul></li>
</ul>
<p><br></p>
<ul>
<li><p><strong>Regression Analysis</strong></p>
<ol style="list-style-type: decimal">
<li><p>y = continuous : Linear Regression</p></li>
<li><p>y = discrete (2 categories) : Logistic Regression</p></li>
<li><p>y = discrete (&gt; 2 categories) : Multinominal / Ordinal Regression</p></li>
<li><p>y = Count : Poisson / Negative Binominal REgression (<em>var &gt; mean</em>)</p></li>
<li><p>Excessive Zero :</p>
<ul>
<li>ZIP (Zero Inflated Position)</li>
<li>ZINB (Zero Inflated Negative Binomial)</li>
<li>Hurdle</li>
</ul></li>
</ol></li>
<li><p>KNN</p></li>
<li><p>Naive Bayes</p></li>
<li><p><strong>Black Box</strong></p>
<ul>
<li>Neural Network</li>
<li>Support Vector Machine</li>
</ul></li>
<li><p><strong>Ensemble</strong></p>
<ul>
<li><p><strong>Stacking</strong> : Multi Techniques (Linear + DT + KNN) mean or majority</p></li>
<li><p><strong>Bagging</strong> : Randon Forest - good for discrete</p></li>
<li><p><strong>Boosting</strong>: Decistion tree, Gradient boosting, XGB, AdaBoost</p></li>
</ul></li>
</ul>
<p><br></p>
<ul>
<li><p><strong>Unsupervised Learning</strong></p>
<ul>
<li><p><strong>Cluster / Segmentation</strong> - <em>reduce Row</em></p>
<ol style="list-style-type: decimal">
<li><strong>Kmeans</strong> - non hierarchical - elbow curve</li>
<li><strong>Hierarchical</strong> - agglomerative - deprogram</li>
<li><strong>DBSCAN</strong> - application with noise</li>
<li><strong>OPTICS</strong> - ordering points to identify cluster structure</li>
<li><strong>CLARA</strong> - cluster large application - for large datasets</li>
<li><strong>K-medians / K-medoids</strong> (for lot of outlines) / <strong>K-modes</strong> (lot of categorical variables)</li>
</ol></li>
</ul>
<p><strong>Dimension Reduction</strong> - <em>reduce columns</em></p>
<ul>
<li><p>PCA</p></li>
<li><p>SVD</p></li>
<li><p><strong>Association Rules / Market Basket Analysis / Affinity Analysis</strong></p>
<ul>
<li>Support</li>
<li>Confidence</li>
<li>EFT Ration &gt; 1</li>
</ul></li>
<li><p><strong>Recommended system</strong></p></li>
<li><p><strong>Network Analysis</strong></p>
<ul>
<li><ol style="list-style-type: decimal">
<li>Degree</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>Page rank</li>
</ol></li>
<li><ol start="3" style="list-style-type: decimal">
<li>others</li>
</ol></li>
</ul></li>
<li><p><strong>Test Mining / NLP</strong></p>
<ul>
<li>Bow</li>
<li>TDW / DTW</li>
<li>TF / TDIDF</li>
</ul></li>
<li><p><strong>Forecasting / Time Series</strong></p>
<ul>
<li><p>Model Based Approaches</p>
<ol style="list-style-type: decimal">
<li><p>Trend: Linear, Exponential , Quadratic</p></li>
<li><p>Seasonality : additive or multiplicative</p></li>
</ol></li>
</ul></li>
<li><p>Data Base Approaches</p>
<ol style="list-style-type: decimal">
<li>AR - Auto regressive</li>
<li>MA - Movie average</li>
<li>ES - Exponential smoothing</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>SES</li>
<li>HOHS / Double Exponential Smoothing</li>
<li>Winters, others</li>
</ol></li>
<li><p>Overtiffing (<em>variance</em>) vs Underfitting (<em>Bias</em>)</p></li>
</ul></li>
</ul>
<p><br></p>
<ul>
<li>Reinforcement Learning (<em>learning from rewards</em>)</li>
</ul>
<p><br></p>
<ul>
<li>Semi-supervised learning</li>
</ul>
<p><br></p>
<ul>
<li>Active learning, transfer learning, structure prediction</li>
</ul>
</div>
<div id="evaluation" class="section level5 hasAnchor">
<h5><span class="header-section-number">9.6.1.3.5</span> 5. Evaluation<a href="data-science.html#evaluation" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>There are no better type of evaluate need to analyze the problem and data / results to select the best metric</p>
<ul>
<li>Mean Error</li>
<li>Mean Absolute deviation</li>
<li>Mean Squared Error</li>
<li>Root Mean Squared Error</li>
<li>Mean Percentage Error</li>
<li>Mean Absolute percentage error</li>
</ul>
<p>For Categorical we also have the <strong>Confustion Matrix</strong></p>
<p><img src="img/confusion%20matrix.png" width="80%" /></p>
<ul>
<li><strong>TP</strong> : Correct Predictive Positive</li>
<li><strong>TN</strong> : Correct Predictive Negative</li>
<li><strong>FP</strong> : Incorrect Predictive Positive</li>
<li><strong>FN</strong> : Incorrect Predict Negative</li>
</ul>
<p><strong>Precision</strong> : Prob of correctly identify a random patient with disease have a disease. (<em>Positive Correct predicted</em>)</p>
<p><strong>Sensitive</strong> (<em>Recall</em> or <em>Hit Rate</em>): Proportion of people with disease who are correctly identified as having disease</p>
<p><strong>Specificity</strong> (<em>True Negative Rate</em>) : Proportion of people with NO disease being characterized as not have disease</p>
<p><strong>FP Rate </strong> (<em>Type 1 error</em>) : 1 - Specificity</p>
<p><strong>FN Rate </strong> (<em>Type 2 error</em>) : 1 - Sensitivity</p>
<p><strong>F1</strong> : 1 to 0 Measure that balance precision and recall</p>
<p><br></p>
<p><strong>ROC</strong></p>
<p><img src="img/roc.png" width="80%" /></p>
<p><strong>AUC</strong> : Are under the curve</p>
<ul>
<li>0.9 - 1.0 : outstanding</li>
<li>0.8 - 0.9 : good</li>
<li>0.7 - 0.8 : acceptable</li>
<li>0.6 - 0.7 : poor</li>
<li>0.5 - 0.5 : no discrimination</li>
</ul>
<p><br></p>
<p><strong>Model Assessment</strong></p>
<ul>
<li>Model performance and success criteria agreed upon early are in sync</li>
<li>Model should be repeatable and reproducible</li>
<li>Model is in line with Non-functional requirements, such as scale, robust, maintainable, easy to deploy</li>
<li>Model evaluation gives satisfactory results</li>
<li>Model is meeting business requirements</li>
</ul>
<p><br></p>
<ul>
<li><p>Rank final models based on the quality of results and relevance</p></li>
<li><p>Any assumptions or constants that were invalidated by the model ?</p></li>
<li><p>Cost of deploy the entire pipeline</p></li>
<li><p>Any pain points</p></li>
<li><p>Data Sufficiency report</p></li>
<li><p>Final suggestions, feedback</p></li>
</ul>
<p><strong>Monitoring</strong> : PEST or SWOT</p>
</div>
<div id="deploy" class="section level5 hasAnchor">
<h5><span class="header-section-number">9.6.1.3.6</span> 6. Deploy<a href="data-science.html#deploy" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<blockquote>
<p>DEV to PROD</p>
</blockquote>
<ul>
<li>Proper resources - Hardware, server, software , human</li>
<li>model saved and then deployed</li>
<li>Maintenance and monitoring (<em>PEST</em>)</li>
</ul>
</div>
</div>
</div>
<div id="statistics-for-data-analysis-using-python" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.6.2</span> Statistics for Data Analysis Using Python<a href="data-science.html#statistics-for-data-analysis-using-python" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="descriptive-statistics" class="section level4 hasAnchor">
<h4><span class="header-section-number">9.6.2.1</span> Descriptive Statistics<a href="data-science.html#descriptive-statistics" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Central Tendency</strong></p>
<ul>
<li><em>Mean</em> : Average</li>
<li><em>Mode</em> : Most occuring number</li>
<li><em>Median</em> : Moddle value when arranged in asc or desc order</li>
</ul>
<p><strong>Dispersion</strong></p>
<ul>
<li><em>Range</em> : highest - lowest value</li>
<li><em>Standard Deviation</em> : squared root of variance</li>
<li><em>Variance</em></li>
<li><em>Inter Quartile Range <strong>IQR</strong></em> : If divide the data into four parts (Q1, Q2 and Q3)
<ul>
<li>Quantiles, if we divide the data into <em>n</em> parts, we get (n-1) points of split called quantiles</li>
</ul></li>
</ul>
</div>
<div id="distributions" class="section level4 hasAnchor">
<h4><span class="header-section-number">9.6.2.2</span> Distributions<a href="data-science.html#distributions" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>BINOMIAL</strong></p>
<ul>
<li>The experiment consist of n repeated trials</li>
<li>Each trial can result in just two possible outcomes(success and failure)</li>
<li>The probability of success, denoted by p, is the same on every trial</li>
<li>The trials are independent, that is, the outcome on one trial does not affect the outcome of other trials</li>
</ul>
<p><em>In Python</em></p>
<pre><code>from scypy.stats import binom

binom.cdf(k , n , p) # cumulative distibution function - for less than or equal to 2
binom.pmf(k , n , p) # Probability mass function - for specific number of, defects
binom.sf(k , n , p)  # for more than 2 (similar 1 - cdf)
binom.mean(n, p)     # for mean of the dist
binom.std(n, p)      # for standard deviation of the dist
binom.var(n, p)      # for the variance of the dist
</code></pre>
<p><br></p>
<p><strong>POISSON</strong></p>
<ul>
<li><p>The possibilities of success are infinite (<em>Number of people in a queue, Number of accident in a city</em>) are sample of this distribution</p></li>
<li><p>Measure the number of success similar to binomial</p></li>
<li><p>As binomial are for discrete distribution</p></li>
<li><p>Properties :</p>
<ul>
<li>The experiment results in a success or failure</li>
<li>The <strong>mean</strong> of success occurs in a specific region <strong>is known</strong></li>
<li>Outcomes are random</li>
<li>The outcomes of interest are rare relative to the possible outcomes</li>
<li>The variance is equal to mean</li>
</ul></li>
</ul>
<p><em>In Python</em></p>
<pre><code>
from scypy.stats import binom

poisson.cdf(k , mu) # cumulative distribution function - for less than or equal to 
poisson.pmf(k , mu) # probability mass function - for exact value
poisson.sf(k , mu)  # for more than (similar 1 - cdf)
poisson.mean(mu)    # for mean of the distr
poisson.var(mu)     # for variance of the distr
poisson.std(mu)     # for standard deviation of the distr

</code></pre>
<p><br></p>
<p><strong>NORMAL</strong></p>
<p>Most common distribution for continuous data</p>
<p><img src="img/normal_distr.png" width="80%" /></p>
<ul>
<li>Properties :
<ul>
<li>Normal distribution is <strong>symmetrically</strong></li>
<li>Long Tails / <strong>Bell shaped</strong></li>
<li>Mean, mode and median are the same</li>
<li><strong>68%</strong> of area under the curve falls with <code>1</code> std of the mean</li>
<li><strong>95%</strong> of area under the curve falls with <code>2</code> std of the mean</li>
<li><strong>99.7%</strong> of area under the curve fall with <code>3</code> std of the mean</li>
<li>The total area under the normal curve is equal to <code>1</code></li>
<li>The probability of any particular value is <code>0</code></li>
<li>The probability that X is greater than or less than a value = area</li>
</ul></li>
</ul>
<pre><code>norm.cdf(x,mu,sigma) # Cumulative distribution function - for less than or equal to 
norm.pdf(x,mu,sigma) # Probability density function (not Probability mass function) - for exact value
norm.sf(x,mu,sigma)  # For more than (similar to 1-cdf)
norm.mean(mu)        # For mean of the distribution
norm.var(mu)         # For variance of the distribution
norm.std(mu)         # For standard deviation of the distribution</code></pre>
</div>
<div id="inferencial-and-hypothesis-testing" class="section level4 hasAnchor">
<h4><span class="header-section-number">9.6.2.3</span> Inferencial and Hypothesis Testing<a href="data-science.html#inferencial-and-hypothesis-testing" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><em>Inferencial Stats</em></p>
<ul>
<li>We infer about the population based on sample data</li>
</ul>
<p><img src="img/sampling_popu.png" width="80%" /></p>
<p><br></p>
<p><em>Central Limit Theorem</em></p>
<ul>
<li><p>For almost all porpulations, the <strong>sampling distribution of the mean</strong> can be <strong>approximated</strong> closely by a <strong>normal distribution</strong>, provided the sample size sufficiently large</p></li>
<li><p>If a variable has a mens of  and the variance <span class="math inline">\(^{2}\)</span>, as the sample size increase, the sample mean approaches a normal distribution with mean <span class="math inline">\(\overline{x}\)</span> and variance <span class="math inline">\(\frac{2}{x}\)</span></p></li>
</ul>
<p><br></p>
<p><em>Hypothesis Testing</em></p>
<ul>
<li>Hypothesis testing is a method of statistical inference</li>
<li>Commonly used tests include
<ul>
<li>Comapre sample statistics with the population parameter</li>
<li>Compare two datasets</li>
</ul></li>
</ul>
<p><br></p>
<p><em>Steps for Hypothesis Testing</em></p>
<blockquote>
<p>Taking a sample and based on that sample we are predictin about the population</p>
</blockquote>
<ol style="list-style-type: decimal">
<li>State the <strong>alternative hypothesis</strong></li>
<li>State the <strong>null hypothesis</strong></li>
<li>Select a probability of <strong>error level</strong> (<em>alpha</em>). generally <strong>0.05</strong></li>
<li>Calculate the <strong>test statistics</strong>(e.g t or z score)
<ul>
<li>z = (x-)/ (<em>Basic one sample</em>)</li>
<li>z = (x  ) / ( / n) (<em>multiple samples</em>)</li>
</ul></li>
<li>Critical test statistic
<ul>
<li>Use the <span class="math inline">\(\alpha\)</span> and check on Test Table</li>
</ul></li>
<li><strong>Interpret</strong> the results</li>
</ol>
<ul>
<li><p><strong>Null Hypothesis</strong> : Basic assumption, for example : <em>The person is innocent</em></p></li>
<li><p><strong>Alternate Hypothesis</strong> : You need to provide proof of this, for example : <em>The person is guilty</em></p></li>
<li><p>In Statistical terms you:</p>
<ul>
<li>Reject the <em>Null Hypothesis</em>, or</li>
<li>Fail to reject the <em>Null Hypothesis</em> (not accept the Null Hypothesis)</li>
</ul></li>
</ul>
<p><img src="img/hypothesis_error.png" width="80%" /></p>
<ul>
<li><strong>Type I Error</strong> :
<ul>
<li>False Alarm</li>
</ul></li>
<li><strong>Type II Error</strong> :
<ul>
<li>Something change and we fail to detect the change</li>
</ul></li>
</ul>
<p><img src="img/type1_type2_error_table.png" width="80%" /></p>
<ul>
<li><strong>Confidence level</strong> : C = 0.90, 0.95, 0.99 (90%, 95%, 99%)</li>
<li><strong>Level of Significance or Type I Error</strong> : <span class="math inline">\(\alpha\)</span> = 1 - C(0.10, 0.05, 0.01)</li>
</ul>
<p><br></p>
<ul>
<li><strong>Power</strong>
<ul>
<li>Power : 1 - <span class="math inline">\(\beta\)</span> (<em>or 1 - type II error</em>)</li>
<li>Type II Error : Fail to reject null hypothesis when null hypothesis is false</li>
<li>Likelihood of rejecting null hypothesis when null hypothesis is false</li>
<li>Or : Power is the ability of a test to correctly reject the null hypothesis</li>
</ul></li>
</ul>
<p><br></p>
<ul>
<li><strong>P-value</strong>
<ul>
<li><em><strong>p-value</strong></em> is the lowest value of alpha for which the null hypothesis can be rejected. (<em>Probability that the null hypothesis is correct</em>)</li>
<li>For example, <strong>if p = 0.045 you can reject the null hypothesis</strong> at <span class="math inline">\(\alpha\)</span> = 0.05</li>
</ul></li>
</ul>
<blockquote>
<p><strong>p</strong> is low the null must go (<em>null get rejected</em>), if <strong>p</strong> is high the null fly (<em>null stay</em>)</p>
</blockquote>
<p><br></p>
<p><em>Proportions &amp; Variances</em></p>
<ul>
<li><p>Conditions for z Test</p>
<ul>
<li><strong>Random</strong> samples</li>
<li>Each observation should be independent of other
<ul>
<li>Sample <strong>with replacement</strong>, or</li>
<li>If sample without replacement, the sample size should <strong>not be more than 10% of population</strong></li>
</ul></li>
<li>Sampling <strong>distribution approximates Normal</strong> Distribution
<ul>
<li>Population is Normally distributed and the population <strong>standard deviation is known</strong> , or</li>
<li>Sample <strong>size &gt;= 30</strong></li>
</ul></li>
</ul></li>
</ul>
<p><br></p>
<p><img src="img/type_of_tests.png" width="80%" /></p>
<ul>
<li><p><em><strong>One Sample</strong></em></p>
<ul>
<li><strong>One Sample z Test</strong> : Used when we have one sample from one machine
<ul>
<li>Conditions for <strong>z</strong> test:
<ul>
<li>Random Samples</li>
<li>Each observation should be independent of each other (<em>sample with replacement</em>) or (<em>if sample without replacement</em> sample size should not be more than 10% or population)</li>
<li>Sample distribution approximates Normal Distribution (<em>Population is Normally distributed and the population std dev is <u><strong>known</strong></u> or size <strong>&gt;= 30</strong></em>)</li>
</ul></li>
</ul></li>
<li><strong>One Sample t Test</strong> : When we have <em>less than 30 numbers of sample</em> and we do not <em>know the population standard deviation</em>
<ul>
<li>Conditions for <strong>t</strong> test:
<ul>
<li>Random samples</li>
<li>Each observation should be independent of each other (<em>sample with replacement</em>) or (<em>if sample without replacement</em> sample size should not be more than 10% or population)</li>
<li>Sample distribution approximates Normal Distribution (<em>Population is Normally distributed and the population std dev is <u><strong>unknown</strong></u> or size <strong>&lt; 30</strong></em>)</li>
</ul></li>
</ul></li>
<li><strong>One Proportion Test</strong> : Compare proportions
<ul>
<li>Conditions for <strong>One Proportion</strong> test
<ul>
<li>Random samples</li>
<li>Each observation should be independent of each other (<em>sample with replacement</em>) or (<em>if sample without replacement</em> sample size should not be more than 10% or population)</li>
<li>The data contains only two categories, such as <u><strong>pass / fail</strong></u> or <u><strong>yes / no</strong></u></li>
<li>For Normal Approximation (both np &gt;= 10 and n(n-p) &gt;= 10 - data should have at least 10 successes and at least 10 failures)</li>
</ul></li>
</ul></li>
<li><strong>One Variance Test</strong> : Check if variance has changed
<ul>
<li>Conditions for <strong>One Variance</strong> test
<ul>
<li>Random samples</li>
<li>Each observation should be independent of each other (<em>sample with replacement</em>) or (<em>if sample without replacement</em> sample size should not be more than 10% or population)</li>
<li>The data follows a <em>Normal Distribution</em></li>
<li><u>Variance Tests</u>
<ul>
<li><strong>Chi-square</strong> Test
<ul>
<li>For testing the population variance against a specified value</li>
<li>Testing goodness of fit of some probability distribution</li>
<li>Testing for independence of two attributes (<em>Contingency Tables</em>)</li>
</ul></li>
<li><strong>F-test</strong>
<ul>
<li>for testing equality of <strong>two</strong> variances from different population</li>
<li>for testing equality of several means with technique of <strong>ANOVA</strong></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><p><em><strong>Two Samples</strong></em></p>
<ul>
<li><p><strong>Two Sample z Test</strong> : Compare the sample (<em>mean</em>) from two machines</p>
<ul>
<li>Conditions for <strong>z</strong> test:
<ul>
<li>Random Samples</li>
<li>Each observation should be independent of each other (<em>sample with replacement</em>) or (<em>if sample without replacement</em> sample size should not be more than 10% or population)</li>
<li>Sample distribution approximates Normal Distribution (<em>Population is Normally distributed and the population std dev is <u><strong>known</strong></u> or size <strong>&gt;= 30</strong></em>)</li>
<li><em>Sample of Z test hypothesis for two sample</em>:
<ul>
<li>Null Hypothesis : 1 = 2</li>
<li>Alternative hypothesis : 1 != 2</li>
<li><a href="https://cran.r-project.org/web/packages/distributions3/vignettes/two-sample-z-test.html">R sample</a></li>
<li><a href="https://www.geeksforgeeks.org/z-test/">Python sample</a></li>
</ul></li>
</ul></li>
</ul></li>
<li><p><strong>Two Sample t test</strong></p>
<ul>
<li>Conditions for <strong>t</strong> test:
<ul>
<li><p>Random Samples</p></li>
<li><p>Each observation should be independent of each other (<em>sample with replacement</em>) or (<em>if sample without replacement</em> sample size should not be more than 10% or population)</p></li>
<li><p>Sample distribution approximates Normal Distribution (<em>Population is Normally distributed and the population std dev is <u><strong>unknown</strong></u> or size <strong>&lt; 30</strong></em>)</p></li>
<li><p>How to calculate ?</p>
<ul>
<li>Variance equal
<ul>
<li>Since we have a small size of sample we going to use t test independent <code>stats.ttest_ind()</code> function</li>
</ul></li>
</ul>
<pre><code>import scipy.stats as stats

machine1 = [150,152,154,152,151]
machine2 = [156,155,158,155,154]

stats.ttest_ind(machine1, machine2, equal_var=True)

#Output
# Statistics = -4.0055
# pvalue     =  0.0039
</code></pre>
<p><strong>Result</strong>
<em>Since the value of pvalue is less than 0.05 we will reject the Null Hypotheses H0 since there is no significant difference in the variance of two machines</em></p>
<ul>
<li>Variance unequal
<ul>
<li>Since we have a small size of sample we going to use t test independent <code>stats.ttest_ind()</code> function</li>
</ul></li>
</ul>
<pre><code>import scipy.stats as stats

machine1 = [150,152,154,152,151]
machine3 = [144,162,177,150,140]

stats.ttest_ind(machine1, machine3, equal_var=False)

#Output
# Statistics =  0.4146
# pvalue     =  0.6992
</code></pre>
<p><strong>Result</strong>
<em>Since <strong>pvalue</strong> is high than 0.05 we will fail reject the Null Hypotheses H0 since there is significant difference in the variance of two machines</em></p></li>
</ul></li>
</ul></li>
<li><p><strong>Paired t test</strong> : Compare when you have before and after results</p>
<ul>
<li><em>If the value in one sample affect the value in the other sample, then <strong>the samples are dependent</strong> : (Ex: Blood pressure before and after specific medicine)</em></li>
<li>How to calculate ?
<ul>
<li>Find the difference between two set of readings as d1, d2..dn</li>
<li>Find the mean and <em>std dev</em> of these differences</li>
<li>Using Python we can use the package <code>scipy.stats</code> and <code>ttest_rel</code> function</li>
</ul>
<pre><code>import scipy.stats as stats

before = [120,122,143,100,109]
after  = [122,120,141,109,109]

stats.ttest_rel(before, after)

# output
# statistics = -0.068
# pvalue     =  0.530</code></pre>
<strong>Results:</strong>
<em>Since <strong>pvalue</strong> is high to 0.05 we fail to reject the H0 (null hypothesis), which means there are no significant difference between the values before and after</em></li>
</ul></li>
<li><p><strong>Two Proportions Test</strong> : Compare the <em>proportions</em> from two samples</p>
<ul>
<li><p>Conditions for <strong>Proportions test</strong></p>
<ul>
<li>Random Samples</li>
<li>Each observation should be independent of each other (<em>sample with replacement</em>) or (<em>if sample without replacement</em> sample size should not be more than 10% or population)</li>
<li>The data contains only two categories, such as pass/fail or yes/no</li>
<li>For Normal approximation :
<ul>
<li>both np &gt;= 10 and np(1-p) &gt;= 10 : Data should have at least 10 successes and at least 10 failures for each sample (<em>some books it is 5</em>)</li>
</ul></li>
</ul></li>
<li><p>Methods to calculate</p>
<ul>
<li>Pooled : H0 : p1 = p2 and Ha p1 != p2</li>
<li>Un-pooled : H0 p1 - p2 = d(difference) and Ha p1 - p2 != d(difference)</li>
</ul></li>
<li><p>How to calculate ?</p>
<pre><code># H0 = p = p0
# Ha = p != p0
# From vendor A we test 200 pieces and find 30 defects
# From vendor B we test 100 pieces and find 10 defects
# Is there a significant difference in quality of those 2 vendors? (95% confidence level)

from  statsmodels.stats.proportion import proportion

proportion.test_proportions_2indep(30,200, 10, 100, method=&#39;score&#39;)


#output
# Statistics = 1.198
# pvalue     = 0.230

</code></pre>
<p><strong>Results:</strong>
<em>Since the pvalue is higher than 0.05 we fail to reject the null hypotheses , we cannot say there is any significant difference in the proportion of this two samples</em></p></li>
</ul></li>
<li><p><strong>Two Variances</strong> : Compare the <em>variances</em> from two samples</p>
<ul>
<li>Conditions and test used for two variance test:
<ul>
<li><strong>F-test</strong>
<ul>
<li>for testing equality of <strong>two</strong> variances from different population</li>
<li>for testing equality of several means with technique of <strong>ANOVA</strong></li>
</ul></li>
</ul></li>
<li>How to calculate ?</li>
</ul>
<pre><code>* 8 samples from machine A : STDEV 1.1
* 5 samples from machine B : STDEV 11  
* Is there a difference in variance at (90% confidence level) ?


from scipy.stats import f

# find f calculated
F_cal = 11/ (1.1**2)
# output 9.09


# find critical values on right dfn =  n - 1
f.isf(0.05, dfn = 4, dfd = 7)
# output : 4.12


# find critical value on left
f.isf(0.95,4,7)
# output 0.16



</code></pre>
<p><strong>Results:</strong>
<em>Since the F_calc(9.09) is in the reject zone higher than right value (4.12), we reject the null hypotheses, there is a significant difference between the machines</em></p>
<p>We also can use <code>stats.bartlett(machine1, machine2)</code> or <code>stats.levene(machine1 , machine2)</code></p>
<p><strong>Levene test is a robust test</strong> compared with Bartlett</p></li>
</ul></li>
<li><p><em><strong>More Than 2 Samples</strong></em></p></li>
</ul>
<blockquote>
<p>ANOVA is Analysis of Variance</p>
</blockquote>
<ul>
<li><p><strong>ANOVA</strong> : If we have 3 or more machines to compare
<em>To analyze the variance we have <strong>chi-square test</strong> for 1 variance test and <strong>F-test</strong> for two variance test</em></p>
<ul>
<li><p>For testing equality of <em>several means</em> with technique of <strong>ANOVA</strong></p></li>
<li><p>H0 : 1 = 2 = 3 = 4  = n <em>(means are equal)</em></p></li>
<li><p>Ha : At least one of the means is different from others <em>(means are NOT equal)</em></p></li>
<li><p>How to calculate ?</p></li>
</ul>
<pre><code>from scipy.stats as stats


m1 = [150,151,152,152,151,150]
m2 = [153,152,148,151,149,152]
m3 = [156,154,155,156,157,155]


stats.f_oneway(m1,m2,m3)

#output:
#statistics : 22.264
#pvalue     : 3.23e-05
</code></pre>
<p><strong>Results:</strong>
<em>As the pvalue is very small we conclude that at least one machine is different from others</em></p>
<p>We can also use the package <code>statsmodels.stats</code> with method <code>oneway.anova_oneway()</code></p></li>
<li><p><strong>ANOVA Concept</strong></p>
<ul>
<li><em>Variation within</em> : Variation of the values in the same machine <em>(inside or ERROR)</em></li>
<li><em>Variation between</em>: Variation of the values between machines <em>(treatment)</em></li>
<li>To check we take the ration of these variations using <strong>F test</strong> to conclude if there are variation of not</li>
</ul></li>
</ul>
<p><br></p>
<ul>
<li><strong>Post Hoc Tests</strong>
<ul>
<li><p>Post Hoc Tests attempt to control the experimentwise error rate <em>(usually alpha = 0.05)</em> just like one-way ANOVA is used instead of multiple t-test</p></li>
<li><p><strong>Tukeys Test</strong> from <code>statsmodels.stats.multicomp</code> method <code>pairwise_tukeyhsd</code></p></li>
</ul>
<pre><code>import statsmodels.stats.oenway as oneway
from statsmodels.stats.multicomp import pairwise_tukeyhsd

df = mpg[mpg[&#39;cylinders&#39;] == 4][[&#39;mpg&#39;, &#39;origin&#39;]]

result = pairwise_tukeyhsd(endog = df[&#39;mpg&#39;] , groups = df[&#39;origin&#39;] , alpha = 0.05 )

print(result)
#output
# p-adj (pvalue) = 0.7995

# Based on result we going to see the there are no significant different between europe and usa

</code></pre></li>
</ul>
<p><br></p>
<ul>
<li><p><strong>Goodmess of Fit Test</strong></p>
<ul>
<li>Use <em>Chi Square</em> as test statistics</li>
<li>To test if the sample is coming from a population with specific distribution</li>
<li>Other goodness-of-fit tests are:
<ul>
<li>Anderson-Darling</li>
<li>Kolmogorov-Smirnov</li>
</ul></li>
<li>H0 : The data follow a specified distribution</li>
<li>Ha : The data do not follow the specified distribution
<ul>
<li>Sample</li>
</ul>
<pre><code>A coin is flipped 100 times. Number of heads (40) and tails(60) . Is this coin biased ? (95% confidence level)

H0 : Coin is not biased
Ha : Coin is biased
alpha = 0.05

# Using python


import scipy.stats as stats

exp = [50,50]
obs = [40,60]

stats.chisquare(f_obs = obs, f_exp = exp)
#output
pvalue = 0.0455

</code></pre>
<strong>Result</strong> : <em>We reject the null hypotheses which means the coin are biased</em></li>
</ul></li>
</ul>
<p><br></p>
<ul>
<li><p><strong>Contingency Tables</strong></p>
<ul>
<li><p>Help to find relationship between two discrete variables</p></li>
<li><p>H0 : Is that there is no relationship between the row and column variables</p></li>
<li><p>Ha : is that there is a relationship (Ha does not tell what type of relationship exists)</p></li>
<li><p>Using python we can use <code>scipy.stats</code></p></li>
</ul>
<pre><code>import scipy.stats as stats

sh_op = np.array([[22,26,23], [28,62,26], [72,22,66]])


stats.chip2_contingency(sh_op)

# output : 
pvalue = 3.45e-10
</code></pre>
<p><strong>Results</strong> : Reject the null hypothesis which means there is a relationship between rows and columns</p></li>
</ul>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="devops.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/11-DataScience.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
